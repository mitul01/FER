{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER_manual_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1YgQfd82sM--d7hn41edHkBeu2jFw6LCx",
      "authorship_tag": "ABX9TyOwJWbl1MZ5KL1W8Sj/ni1l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitul01/FER/blob/main/FER_manual_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WuQYlT2d3xU",
        "outputId": "4fa59306-6b2a-4b19-b685-0ecb9ec321c5"
      },
      "source": [
        "cd /content/drive/MyDrive/colab-20210303T131708Z-001/colab"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab-20210303T131708Z-001/colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6t-o_DTcQWI"
      },
      "source": [
        "from config import emotion_config as config\n",
        "from pipeline.preprocessing import ImageToArrayPreprocessor\n",
        "from pipeline.callbacks import EpochCheckpoint\n",
        "from pipeline.callbacks import TrainingMonitor\n",
        "from pipeline.io import HDF5DatasetGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout,Activation\n",
        "from tensorflow.keras import Sequential"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN1e2UWDdz_l",
        "outputId": "1ff35554-9d9c-49ca-c508-481317f8c6ce"
      },
      "source": [
        "trainAug = ImageDataGenerator(rotation_range = 10, zoom_range = 0.1,\n",
        "    horizontal_flip = True, rescale = 1 / 255.0, fill_mode = \"nearest\")\n",
        "\n",
        "valAug = ImageDataGenerator(rescale = 1 / 255.0)\n",
        "iap = ImageToArrayPreprocessor()\n",
        "\n",
        "# initialize the training and validation dataset generators\n",
        "\n",
        "trainGen = HDF5DatasetGenerator(config.TRAIN_HDF5, config.BATCH_SIZE,\n",
        "    aug = trainAug, preprocessors = [iap], classes = config.NUM_CLASSES)\n",
        "valGen = HDF5DatasetGenerator(config.VAL_HDF5, config.BATCH_SIZE,\n",
        "    aug = valAug, preprocessors = [iap], classes = config.NUM_CLASSES)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab-20210303T131708Z-001/colab/pipeline/io/hdf5datasetgenerator.py:20: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  self.db = h5py.File(dbPath)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diwTx6GpS50E",
        "outputId": "c3171956-4ace-40d0-f0ba-6671723c3f2c"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(64, (1, 1), padding='same', activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add((Conv2D(128, (3, 3),padding='same', activation='relu')))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128, (1, 3),padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3, 1),padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2),padding=\"same\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128, (3,3),padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3),padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3),padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2),padding=\"same\"))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.fit(X_train, Y_train, batch_size=64, epochs=40, steps_per_epoch=(len(X_train)/128))\n",
        "\n",
        "\n",
        "#model.fit(X_train, Y_train, batch_size=64, epochs=40, steps_per_epoch=len(X_train)/128, validation_split = 0.25)\n",
        "batch_size = 32\n",
        "\n",
        "epochs = 100\n",
        "from tensorflow.keras import optimizers\n",
        "optim=optimizers.Adam(0.001)\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0.00005,\n",
        "    patience=7,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "]\n",
        "\n",
        "history=model.fit_generator(\n",
        "    trainGen.generator(),\n",
        "    steps_per_epoch = trainGen.numImages // batch_size,\n",
        "    validation_data = valGen.generator(),\n",
        "    validation_steps = valGen.numImages // batch_size,\n",
        "    epochs = epochs,\n",
        "    callbacks = callbacks,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 48, 48, 64)        128       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 48, 48, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 48, 48, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 48, 48, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 48, 48, 128)       49280     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 48, 48, 128)       49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 48, 48, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 18432)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               2359424   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 3,013,126\n",
            "Trainable params: 3,011,206\n",
            "Non-trainable params: 1,920\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "897/897 [==============================] - 192s 175ms/step - loss: 1.8785 - accuracy: 0.2575 - val_loss: 1.4020 - val_accuracy: 0.4423\n",
            "Epoch 2/100\n",
            "897/897 [==============================] - 159s 177ms/step - loss: 1.4155 - accuracy: 0.4387 - val_loss: 1.2106 - val_accuracy: 0.5216\n",
            "Epoch 3/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 1.2507 - accuracy: 0.5123 - val_loss: 1.1273 - val_accuracy: 0.5692\n",
            "Epoch 4/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 1.1822 - accuracy: 0.5415 - val_loss: 1.0778 - val_accuracy: 0.5830\n",
            "Epoch 5/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 1.1381 - accuracy: 0.5630 - val_loss: 1.0377 - val_accuracy: 0.6026\n",
            "Epoch 6/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 1.0989 - accuracy: 0.5773 - val_loss: 0.9887 - val_accuracy: 0.6223\n",
            "Epoch 7/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 1.0632 - accuracy: 0.5931 - val_loss: 0.9697 - val_accuracy: 0.6393\n",
            "Epoch 8/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 1.0394 - accuracy: 0.6030 - val_loss: 0.9772 - val_accuracy: 0.6247\n",
            "Epoch 9/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 1.0208 - accuracy: 0.6120 - val_loss: 0.9720 - val_accuracy: 0.6356\n",
            "Epoch 10/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.9996 - accuracy: 0.6180 - val_loss: 0.9521 - val_accuracy: 0.6357\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 11/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.9624 - accuracy: 0.6337 - val_loss: 0.9340 - val_accuracy: 0.6493\n",
            "Epoch 12/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.9437 - accuracy: 0.6414 - val_loss: 0.9467 - val_accuracy: 0.6420\n",
            "Epoch 13/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.9289 - accuracy: 0.6494 - val_loss: 0.9264 - val_accuracy: 0.6523\n",
            "Epoch 14/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.9143 - accuracy: 0.6552 - val_loss: 0.9326 - val_accuracy: 0.6500\n",
            "Epoch 15/100\n",
            "897/897 [==============================] - 157s 176ms/step - loss: 0.9052 - accuracy: 0.6580 - val_loss: 0.9201 - val_accuracy: 0.6638\n",
            "Epoch 16/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8925 - accuracy: 0.6640 - val_loss: 0.9146 - val_accuracy: 0.6634\n",
            "Epoch 17/100\n",
            "897/897 [==============================] - 157s 176ms/step - loss: 0.8836 - accuracy: 0.6669 - val_loss: 0.9208 - val_accuracy: 0.6580\n",
            "Epoch 18/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8767 - accuracy: 0.6693 - val_loss: 0.9170 - val_accuracy: 0.6618\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 19/100\n",
            "897/897 [==============================] - 157s 175ms/step - loss: 0.8594 - accuracy: 0.6758 - val_loss: 0.8962 - val_accuracy: 0.6734\n",
            "Epoch 20/100\n",
            "897/897 [==============================] - 157s 176ms/step - loss: 0.8444 - accuracy: 0.6837 - val_loss: 0.8986 - val_accuracy: 0.6694\n",
            "Epoch 21/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8383 - accuracy: 0.6839 - val_loss: 0.8987 - val_accuracy: 0.6736\n",
            "Epoch 22/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8309 - accuracy: 0.6883 - val_loss: 0.8983 - val_accuracy: 0.6653\n",
            "Epoch 23/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8240 - accuracy: 0.6892 - val_loss: 0.8964 - val_accuracy: 0.6715\n",
            "Epoch 24/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8160 - accuracy: 0.6933 - val_loss: 0.8987 - val_accuracy: 0.6682\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 25/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8079 - accuracy: 0.6963 - val_loss: 0.8931 - val_accuracy: 0.6742\n",
            "Epoch 26/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8050 - accuracy: 0.6952 - val_loss: 0.8892 - val_accuracy: 0.6786\n",
            "Epoch 27/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7973 - accuracy: 0.7005 - val_loss: 0.8914 - val_accuracy: 0.6753\n",
            "Epoch 28/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7931 - accuracy: 0.7010 - val_loss: 0.8959 - val_accuracy: 0.6762\n",
            "Epoch 29/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7945 - accuracy: 0.7021 - val_loss: 0.8966 - val_accuracy: 0.6766\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 30/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7870 - accuracy: 0.7036 - val_loss: 0.8928 - val_accuracy: 0.6766\n",
            "Epoch 31/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7815 - accuracy: 0.7050 - val_loss: 0.8980 - val_accuracy: 0.6720\n",
            "Epoch 32/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7852 - accuracy: 0.7054 - val_loss: 0.8980 - val_accuracy: 0.6732\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 33/100\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7788 - accuracy: 0.7066 - val_loss: 0.8966 - val_accuracy: 0.6755\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00033: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blRv_85krIM4",
        "outputId": "74fbd7e1-9872-4dfc-c1f1-bcee520ff13c"
      },
      "source": [
        "optim=optimizers.Adam(0.00001)\n",
        "\n",
        "model.compile(optimizer=optim,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history=model.fit_generator(\n",
        "    trainGen.generator(),\n",
        "    steps_per_epoch = trainGen.numImages // batch_size,\n",
        "    validation_data = valGen.generator(),\n",
        "    validation_steps = valGen.numImages // batch_size,\n",
        "    epochs = 10,\n",
        "    callbacks = callbacks,\n",
        "    verbose = 1\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "897/897 [==============================] - 160s 177ms/step - loss: 0.7957 - accuracy: 0.7018 - val_loss: 0.8891 - val_accuracy: 0.6748\n",
            "Epoch 2/10\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8015 - accuracy: 0.6997 - val_loss: 0.8961 - val_accuracy: 0.6732\n",
            "Epoch 3/10\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8028 - accuracy: 0.6952 - val_loss: 0.8946 - val_accuracy: 0.6731\n",
            "Epoch 4/10\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7963 - accuracy: 0.7011 - val_loss: 0.8944 - val_accuracy: 0.6728\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
            "Epoch 5/10\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7941 - accuracy: 0.7020 - val_loss: 0.8978 - val_accuracy: 0.6731\n",
            "Epoch 6/10\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7992 - accuracy: 0.6996 - val_loss: 0.8933 - val_accuracy: 0.6744\n",
            "Epoch 7/10\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.7955 - accuracy: 0.7008 - val_loss: 0.8925 - val_accuracy: 0.6734\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
            "Epoch 8/10\n",
            "897/897 [==============================] - 158s 176ms/step - loss: 0.8006 - accuracy: 0.7002 - val_loss: 0.8933 - val_accuracy: 0.6737\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtKw8GFXYSL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c13719-6db8-4997-809c-84a6c5a5dc07"
      },
      "source": [
        "testAug = ImageDataGenerator(rescale = 1 / 255.0)\n",
        "iap = ImageToArrayPreprocessor()\n",
        "\n",
        "testGen = HDF5DatasetGenerator(config.TEST_HDF5, config.BATCH_SIZE,\n",
        "    aug = testAug, preprocessors = [iap], classes = config.NUM_CLASSES)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab-20210303T131708Z-001/colab/pipeline/io/hdf5datasetgenerator.py:20: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  self.db = h5py.File(dbPath)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEfibmNTCIZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1279b1f8-f241-40ff-dff7-f329016c7a37"
      },
      "source": [
        "predictions = model.predict_generator(testGen.generator(),steps=testGen.numImages //64, max_queue_size=64*2)\n",
        "\n",
        "(loss, acc) = model.evaluate_generator(\n",
        "\ttestGen.generator(),\n",
        "\tsteps=testGen.numImages // config.BATCH_SIZE,\n",
        "\tmax_queue_size=config.BATCH_SIZE * 2)\n",
        "print(\"[INFO] accuracy: {:.2f}\".format(acc * 100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] accuracy: 65.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfNarPWpYMNB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}