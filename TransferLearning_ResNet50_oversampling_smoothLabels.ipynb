{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_ResNet50_oversampling_smoothLabels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1n4qlGG6aom4F9cFxwUod8qB-eQVvPr8t",
      "authorship_tag": "ABX9TyNCN8UdQgfyqDWPSYezYqTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitul01/FER/blob/main/TransferLearning_ResNet50_oversampling_smoothLabels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibb-suoVu23w"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsfpSp2Zu9ka",
        "outputId": "f4e0ce92-ac55-4461-cec1-fed1737457b1"
      },
      "source": [
        "cd /content/drive/MyDrive/colab-20210303T131708Z-001/colab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab-20210303T131708Z-001/colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppi9U9bC42_U"
      },
      "source": [
        "def make_6_emotions(df):\r\n",
        "  for i in range(len(df)):\r\n",
        "    if df['emotion'][i]==1:\r\n",
        "      df['emotion'][i]==0\r\n",
        "    elif df['emotion'][i]>1:\r\n",
        "      df['emotion'][i]-=1\r\n",
        "  return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFz6VAFCvBho",
        "outputId": "f0684144-dfd7-4781-fd05-c40793f20853"
      },
      "source": [
        "data = pd.read_csv('fer2013/fer2013.csv')\r\n",
        "data= make_6_emotions(data)\r\n",
        "train_data = data[data.Usage=='Training']\r\n",
        "val_data = data[data.Usage=='PublicTest']\r\n",
        "test_data = data[data.Usage=='PrivateTest']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAdvxwMD4hY_"
      },
      "source": [
        "# Oversampling the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x2Z8lOjvMpl",
        "outputId": "238d062f-409c-498c-f092-6506e34876b9"
      },
      "source": [
        "import collections\r\n",
        "import imblearn\r\n",
        "from imblearn.over_sampling import RandomOverSampler\r\n",
        "oversampler = RandomOverSampler()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79VwjNLX4j4s",
        "outputId": "48244473-6753-41e8-c595-2787cf53b1f1"
      },
      "source": [
        "collections.Counter(train_data.emotion)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3995, 1: 4533, 2: 7215, 3: 4830, 4: 3171, 5: 4965})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gc7x_w259uD",
        "outputId": "08b29c08-7fce-47a6-aff5-03897be5f1e1"
      },
      "source": [
        "from keras.utils import to_categorical\r\n",
        "\r\n",
        "x_train, y_train = oversampler.fit_resample(train_data.pixels.values.reshape(-1,1),train_data.emotion.values)\r\n",
        "\r\n",
        "x_val = val_data.pixels.values.reshape(-1,1)\r\n",
        "y_val = val_data.emotion.values\r\n",
        "\r\n",
        "x_test = test_data.pixels.values.reshape(-1,1)\r\n",
        "y_test = test_data.emotion.values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOGpKU8o6aC4",
        "outputId": "dce5ac7d-c610-41cb-ca14-32b344c9756f"
      },
      "source": [
        "collections.Counter(y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 7215, 1: 7215, 2: 7215, 3: 7215, 4: 7215, 5: 7215})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs-33l0B6c5g"
      },
      "source": [
        "x_train = list(x_train)\r\n",
        "x_val   = list(x_val)\r\n",
        "x_test  = list(x_test)\r\n",
        "\r\n",
        "for i,item in enumerate(x_train):\r\n",
        "    x_train[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\r\n",
        "for i,item in enumerate(x_val):\r\n",
        "    x_val[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\r\n",
        "for i,item in enumerate(x_test):\r\n",
        "    x_test[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\r\n",
        "    \r\n",
        "x_train = np.vstack(x_train).reshape(-1,48,48,1)\r\n",
        "x_val = np.vstack(x_val).reshape(-1,48,48,1)\r\n",
        "x_test = np.vstack(x_test).reshape(-1,48,48,1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeRrHcga6iAA"
      },
      "source": [
        "y_train = to_categorical(y_train,num_classes=6)\r\n",
        "y_val   = to_categorical(y_val  ,num_classes=6)\r\n",
        "y_test  = to_categorical(y_test ,num_classes=6)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7yVFs_HNXuN"
      },
      "source": [
        "# Label Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bue_PVUb6k3J"
      },
      "source": [
        "from copy import deepcopy as copy\r\n",
        "\r\n",
        "def smooth_labels(y, smooth_factor):\r\n",
        "    '''Convert a matrix of one-hot row-vector labels into smoothed versions.\r\n",
        "\r\n",
        "    # Arguments\r\n",
        "        y: matrix of one-hot row-vector labels to be smoothed\r\n",
        "        smooth_factor: label smoothing factor (between 0 and 1)\r\n",
        "\r\n",
        "    # Returns\r\n",
        "        A matrix of smoothed labels.\r\n",
        "    '''\r\n",
        "    assert len(y.shape) == 2, 'input should be a batch of one-hot-encoded data'\r\n",
        "    y2 = copy(y)\r\n",
        "    if 0 <= smooth_factor <= 1:\r\n",
        "        # label smoothing ref: https://www.robots.ox.ac.uk/~vgg/rg/papers/reinception.pdf\r\n",
        "        y2 *= 1 - smooth_factor\r\n",
        "        y2 += smooth_factor / y.shape[1]\r\n",
        "    else:\r\n",
        "        raise Exception(\r\n",
        "            'Invalid label smoothing factor: ' + str(smooth_factor))\r\n",
        "    return y2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib5OQn8C_7un"
      },
      "source": [
        "from keras.utils import Sequence\r\n",
        "from keras.applications.resnet50 import preprocess_input\r\n",
        "import cv2\r\n",
        "from math import floor\r\n",
        "\r\n",
        "class data_sequence(Sequence):\r\n",
        "    '''\r\n",
        "      yield sequence of data\r\n",
        "      features -- list of features\r\n",
        "      labels -- list of labels\r\n",
        "      target_channels {int} -- 1 (gray) or 3(RGB)\r\n",
        "    '''\r\n",
        "    def __init__(self, features, labels, batch_size=128, target_dim=(224,224), \r\n",
        "                 n_classes=6, shuffle=True, smooth=0.0):\r\n",
        "        'Initialization'\r\n",
        "        assert len(features)==len(labels), 'number of feature and labels not consistent'\r\n",
        "        self.features = features\r\n",
        "        self.labels = labels\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.target_dim = target_dim\r\n",
        "        self.target_channels = 3\r\n",
        "        self.n_classes = n_classes\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.smooth = smooth\r\n",
        "        self.sample_count = len(labels)\r\n",
        "        self.indexes = np.arange(self.sample_count)\r\n",
        "        self.on_epoch_end()\r\n",
        "#         self.verbose = verbose\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        'Denotes the number of batches per epoch'\r\n",
        "        return floor(self.sample_count / self.batch_size)\r\n",
        "\r\n",
        "    def __gray2RGB__(self,x):\r\n",
        "      if len(x.shape)==2:\r\n",
        "        return np.stack((x,x,x),-1)\r\n",
        "      else:\r\n",
        "        assert len(x.shape)==3\r\n",
        "        if len(x[0,0,:]) == 1:\r\n",
        "          return np.stack((x[:,:,0],x[:,:,0],x[:,:,0]),-1)\r\n",
        "        else:\r\n",
        "          assert len(x[0,0,:])==self.target_channels\r\n",
        "      return x\r\n",
        "\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "        'Generate one batch of data'\r\n",
        "        # Generate indexes of the batch\r\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\r\n",
        "        X = np.empty((self.batch_size, *self.target_dim, self.target_channels))\r\n",
        "        Y = np.empty((self.batch_size, self.n_classes))\r\n",
        "        for i,ind in enumerate(indexes):\r\n",
        "          x = self.features[ind]\r\n",
        "          # resize image to the target size \r\n",
        "          x = cv2.resize(x,self.target_dim,interpolation=cv2.INTER_CUBIC)\r\n",
        "          x = self.__gray2RGB__(x)\r\n",
        "          X[i] = preprocess_input(x) # or version=2 for VGGFace2 ResNet50  \r\n",
        "          y = self.labels[ind]\r\n",
        "          if isinstance(y,int):\r\n",
        "            Y[i]=to_categorical(y,7)\r\n",
        "          else:\r\n",
        "            assert len(y)==self.n_classes\r\n",
        "            Y[i]=y\r\n",
        "        X = np.array(X)\r\n",
        "        Y = np.array(Y)\r\n",
        "        if self.smooth > 0.0:\r\n",
        "          smooth_labels(Y, self.smooth)\r\n",
        "        return X,Y\r\n",
        "\r\n",
        "    def on_epoch_end(self):\r\n",
        "        'Updates indexes after each epoch'\r\n",
        "        if self.shuffle == True:\r\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdvyGOpnBR6Q"
      },
      "source": [
        "train_sequence = data_sequence(x_train,y_train,batch_size=16,target_dim=(224,224),n_classes=6,shuffle=False)\r\n",
        "feature,lable = train_sequence.__getitem__(0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Qm38XTBf5b"
      },
      "source": [
        "emotion_dict = {0: 'Angry',1: 'Fear', 2: 'Happy', 3: 'Sad', 4: 'Surprise', 5:'Neutral'}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS21WTK9EL1l",
        "outputId": "8d231fb8-c24e-4ebe-fcba-f8671e5ccf73"
      },
      "source": [
        "!pip install keras-vggface\r\n",
        "!pip install keras_applications\r\n",
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-vggface\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/7d/5f0319ebdc09ac1a2272364fa9583f5067b6f8aff93fbbf8835d81cbaad7/keras_vggface-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (7.0.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.10.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.4.3)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n",
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_2zFgjtEF7p",
        "outputId": "5736435b-b0fa-4a18-f85a-689b3bdf1df1"
      },
      "source": [
        "vggface = VGGFace(model='resnet50', include_top=False, input_shape = (224,224,3))\r\n",
        "vggface.trainable = False\r\n",
        "vggface.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 3s 0us/step\n",
            "Model: \"vggface_resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 23,561,152\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,561,152\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLWquPTkEKoO",
        "outputId": "9ac85c50-f5f1-40ca-c8b4-092dddbc9ed0"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Flatten\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import Dropout\r\n",
        "from keras.layers import BatchNormalization\r\n",
        "\r\n",
        "# model = Sequential([vggface,\r\n",
        "#                     Flatten(),\r\n",
        "#                     Dropout(0.5),\r\n",
        "#                     BatchNormalization(),\r\n",
        "#                     Dense(128, activation='relu'),\r\n",
        "#                     Dropout(0.5),\r\n",
        "#                     BatchNormalization(),\r\n",
        "#                     Dense(len(emotion_dict), activation='softmax', name = 'classifer')])\r\n",
        "model = Sequential([vggface,\r\n",
        "                    Flatten(),\r\n",
        "                    Dropout(0.25),\r\n",
        "                    Dense(2048, activation='relu'),\r\n",
        "                    Dropout(0.25),\r\n",
        "                    Dense(1024, activation='relu'),\r\n",
        "                    Dense(6, activation='softmax', name = 'classifer')])\r\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vggface_resnet50 (Functional (None, 1, 1, 2048)        23561152  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "classifer (Dense)            (None, 6)                 6150      \n",
            "=================================================================\n",
            "Total params: 29,861,830\n",
            "Trainable params: 6,300,678\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGa11LWgEopS"
      },
      "source": [
        "# train_sequence = data_sequence(x_train,y_train,batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.07)\r\n",
        "# val_sequence   = data_sequence(x_val,  y_val,  batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\r\n",
        "# test_sequence  = data_sequence(x_test, y_test, batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\r\n",
        "\r\n",
        "train_sequence = data_sequence(x_train,y_train,batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.07)\r\n",
        "val_sequence   = data_sequence(x_val,  y_val,  batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\r\n",
        "test_sequence  = data_sequence(x_test, y_test, batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0avPy4szExop",
        "outputId": "2a27258d-2ce3-4a79-d6a9-636e4c26f773"
      },
      "source": [
        "EPOCHS=100\r\n",
        "\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\r\n",
        "\r\n",
        "model.compile(optimizer = Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "\r\n",
        "early_stopping = EarlyStopping(\r\n",
        "    monitor='val_accuracy',\r\n",
        "    min_delta=0.00005,\r\n",
        "    patience=7,\r\n",
        "    verbose=1,\r\n",
        "    restore_best_weights=True,\r\n",
        ")\r\n",
        "\r\n",
        "lr_scheduler = ReduceLROnPlateau(\r\n",
        "    monitor='val_accuracy',\r\n",
        "    factor=0.5,\r\n",
        "    patience=7,\r\n",
        "    min_lr=1e-7,\r\n",
        "    verbose=1,\r\n",
        ")\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    early_stopping,\r\n",
        "    lr_scheduler,\r\n",
        "]\r\n",
        "\r\n",
        "hist = model.fit_generator(generator = train_sequence,\r\n",
        "                           validation_data = val_sequence,\r\n",
        "                           callbacks=callbacks,\r\n",
        "                           epochs = EPOCHS)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1352/1352 [==============================] - 167s 98ms/step - loss: 1.7279 - accuracy: 0.4813 - val_loss: 1.0752 - val_accuracy: 0.5951\n",
            "Epoch 2/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.9999 - accuracy: 0.6176 - val_loss: 1.0343 - val_accuracy: 0.6091\n",
            "Epoch 3/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.8719 - accuracy: 0.6755 - val_loss: 0.9917 - val_accuracy: 0.6286\n",
            "Epoch 4/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.7701 - accuracy: 0.7169 - val_loss: 1.0149 - val_accuracy: 0.6317\n",
            "Epoch 5/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.6806 - accuracy: 0.7531 - val_loss: 1.0236 - val_accuracy: 0.6403\n",
            "Epoch 6/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.6019 - accuracy: 0.7842 - val_loss: 1.0592 - val_accuracy: 0.6465\n",
            "Epoch 7/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.5340 - accuracy: 0.8086 - val_loss: 1.0305 - val_accuracy: 0.6546\n",
            "Epoch 8/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.4828 - accuracy: 0.8296 - val_loss: 1.0898 - val_accuracy: 0.6532\n",
            "Epoch 9/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.4446 - accuracy: 0.8437 - val_loss: 1.1291 - val_accuracy: 0.6507\n",
            "Epoch 10/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.4048 - accuracy: 0.8596 - val_loss: 1.1123 - val_accuracy: 0.6521\n",
            "Epoch 11/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.3788 - accuracy: 0.8697 - val_loss: 1.1470 - val_accuracy: 0.6599\n",
            "Epoch 12/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.3582 - accuracy: 0.8740 - val_loss: 1.1949 - val_accuracy: 0.6423\n",
            "Epoch 13/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.3290 - accuracy: 0.8854 - val_loss: 1.1807 - val_accuracy: 0.6641\n",
            "Epoch 14/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.3101 - accuracy: 0.8949 - val_loss: 1.2312 - val_accuracy: 0.6688\n",
            "Epoch 15/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.2997 - accuracy: 0.8975 - val_loss: 1.2653 - val_accuracy: 0.6613\n",
            "Epoch 16/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.2766 - accuracy: 0.9046 - val_loss: 1.2461 - val_accuracy: 0.6543\n",
            "Epoch 17/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.2681 - accuracy: 0.9096 - val_loss: 1.3438 - val_accuracy: 0.6554\n",
            "Epoch 18/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.2582 - accuracy: 0.9136 - val_loss: 1.2935 - val_accuracy: 0.6565\n",
            "Epoch 19/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.2387 - accuracy: 0.9187 - val_loss: 1.3021 - val_accuracy: 0.6638\n",
            "Epoch 20/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.2350 - accuracy: 0.9206 - val_loss: 1.3338 - val_accuracy: 0.6557\n",
            "Epoch 21/100\n",
            "1352/1352 [==============================] - 134s 99ms/step - loss: 0.2261 - accuracy: 0.9226 - val_loss: 1.3279 - val_accuracy: 0.6610\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 00021: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqCCaS7QMdOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8601c89-1315-4c8b-e90a-6ae7c541aa03"
      },
      "source": [
        "model.evaluate(test_sequence)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "112/112 [==============================] - 10s 91ms/step - loss: 1.1284 - accuracy: 0.6783\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1283671855926514, 0.6782923936843872]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9q4DZqeQr72"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}