{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_ResNet50_oversampling_smoothLabels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1n4qlGG6aom4F9cFxwUod8qB-eQVvPr8t",
      "authorship_tag": "ABX9TyNHqva+FBWGz8RKG1Tpch5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitul01/FER/blob/main/TransferLearning_ResNet50_oversampling_smoothLabels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibb-suoVu23w"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsfpSp2Zu9ka",
        "outputId": "126ee810-bfca-43d2-f4d7-976e0a2d07f1"
      },
      "source": [
        "cd /content/drive/MyDrive/colab-20210303T131708Z-001/colab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab-20210303T131708Z-001/colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppi9U9bC42_U"
      },
      "source": [
        "def make_6_emotions(df):\n",
        "  for i in range(len(df)):\n",
        "    if df['emotion'][i]==1:\n",
        "      df['emotion'][i]==0\n",
        "    elif df['emotion'][i]>1:\n",
        "      df['emotion'][i]-=1\n",
        "  return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFz6VAFCvBho",
        "outputId": "d7ba6dbd-54fc-4349-927c-b710d23b5e3c"
      },
      "source": [
        "data = pd.read_csv('fer2013/fer2013.csv')\n",
        "data= make_6_emotions(data)\n",
        "train_data = data[data.Usage=='Training']\n",
        "val_data = data[data.Usage=='PublicTest']\n",
        "test_data = data[data.Usage=='PrivateTest']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAdvxwMD4hY_"
      },
      "source": [
        "# Oversampling the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x2Z8lOjvMpl",
        "outputId": "9eba2807-8323-4643-e3bd-8a5293458312"
      },
      "source": [
        "import collections\n",
        "import imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversampler = RandomOverSampler()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79VwjNLX4j4s",
        "outputId": "cd6b57c7-bfe1-4847-8e9c-8a21310733d6"
      },
      "source": [
        "collections.Counter(train_data.emotion)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3995, 1: 4533, 2: 7215, 3: 4830, 4: 3171, 5: 4965})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gc7x_w259uD",
        "outputId": "f7ff480a-5988-42d0-c568-2cd4e57c29c2"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "x_train, y_train = oversampler.fit_resample(train_data.pixels.values.reshape(-1,1),train_data.emotion.values)\n",
        "\n",
        "x_val = val_data.pixels.values.reshape(-1,1)\n",
        "y_val = val_data.emotion.values\n",
        "\n",
        "x_test = test_data.pixels.values.reshape(-1,1)\n",
        "y_test = test_data.emotion.values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOGpKU8o6aC4",
        "outputId": "5674ae6e-01c4-4040-d132-be3498f28916"
      },
      "source": [
        "collections.Counter(y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 7215, 1: 7215, 2: 7215, 3: 7215, 4: 7215, 5: 7215})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs-33l0B6c5g"
      },
      "source": [
        "x_train = list(x_train)\n",
        "x_val   = list(x_val)\n",
        "x_test  = list(x_test)\n",
        "\n",
        "for i,item in enumerate(x_train):\n",
        "    x_train[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\n",
        "for i,item in enumerate(x_val):\n",
        "    x_val[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\n",
        "for i,item in enumerate(x_test):\n",
        "    x_test[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\n",
        "    \n",
        "x_train = np.vstack(x_train).reshape(-1,48,48,1)\n",
        "x_val = np.vstack(x_val).reshape(-1,48,48,1)\n",
        "x_test = np.vstack(x_test).reshape(-1,48,48,1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeRrHcga6iAA"
      },
      "source": [
        "y_train = to_categorical(y_train,num_classes=6)\n",
        "y_val   = to_categorical(y_val  ,num_classes=6)\n",
        "y_test  = to_categorical(y_test ,num_classes=6)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7yVFs_HNXuN"
      },
      "source": [
        "# Label Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bue_PVUb6k3J"
      },
      "source": [
        "from copy import deepcopy as copy\n",
        "\n",
        "def smooth_labels(y, smooth_factor):\n",
        "    '''Convert a matrix of one-hot row-vector labels into smoothed versions.\n",
        "\n",
        "    # Arguments\n",
        "        y: matrix of one-hot row-vector labels to be smoothed\n",
        "        smooth_factor: label smoothing factor (between 0 and 1)\n",
        "\n",
        "    # Returns\n",
        "        A matrix of smoothed labels.\n",
        "    '''\n",
        "    assert len(y.shape) == 2, 'input should be a batch of one-hot-encoded data'\n",
        "    y2 = copy(y)\n",
        "    if 0 <= smooth_factor <= 1:\n",
        "        # label smoothing ref: https://www.robots.ox.ac.uk/~vgg/rg/papers/reinception.pdf\n",
        "        y2 *= 1 - smooth_factor\n",
        "        y2 += smooth_factor / y.shape[1]\n",
        "    else:\n",
        "        raise Exception(\n",
        "            'Invalid label smoothing factor: ' + str(smooth_factor))\n",
        "    return y2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib5OQn8C_7un"
      },
      "source": [
        "from keras.utils import Sequence\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "import cv2\n",
        "from math import floor\n",
        "\n",
        "class data_sequence(Sequence):\n",
        "    '''\n",
        "      yield sequence of data\n",
        "      features -- list of features\n",
        "      labels -- list of labels\n",
        "      target_channels {int} -- 1 (gray) or 3(RGB)\n",
        "    '''\n",
        "    def __init__(self, features, labels, batch_size=128, target_dim=(224,224), \n",
        "                 n_classes=6, shuffle=True, smooth=0.0):\n",
        "        'Initialization'\n",
        "        assert len(features)==len(labels), 'number of feature and labels not consistent'\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.target_dim = target_dim\n",
        "        self.target_channels = 3\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.smooth = smooth\n",
        "        self.sample_count = len(labels)\n",
        "        self.indexes = np.arange(self.sample_count)\n",
        "        self.on_epoch_end()\n",
        "#         self.verbose = verbose\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return floor(self.sample_count / self.batch_size)\n",
        "\n",
        "    def __gray2RGB__(self,x):\n",
        "      if len(x.shape)==2:\n",
        "        return np.stack((x,x,x),-1)\n",
        "      else:\n",
        "        assert len(x.shape)==3\n",
        "        if len(x[0,0,:]) == 1:\n",
        "          return np.stack((x[:,:,0],x[:,:,0],x[:,:,0]),-1)\n",
        "        else:\n",
        "          assert len(x[0,0,:])==self.target_channels\n",
        "      return x\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        X = np.empty((self.batch_size, *self.target_dim, self.target_channels))\n",
        "        Y = np.empty((self.batch_size, self.n_classes))\n",
        "        for i,ind in enumerate(indexes):\n",
        "          x = self.features[ind]\n",
        "          # resize image to the target size \n",
        "          x = cv2.resize(x,self.target_dim,interpolation=cv2.INTER_CUBIC)\n",
        "          x = self.__gray2RGB__(x)\n",
        "          X[i] = preprocess_input(x) # or version=2 for VGGFace2 ResNet50  \n",
        "          y = self.labels[ind]\n",
        "          if isinstance(y,int):\n",
        "            Y[i]=to_categorical(y,6)\n",
        "          else:\n",
        "            assert len(y)==self.n_classes\n",
        "            Y[i]=y\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "        if self.smooth > 0.0:\n",
        "          smooth_labels(Y, self.smooth)\n",
        "        return X,Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okNUEp2nRYqV",
        "outputId": "aee83496-f8ec-4ff6-a90c-831db85e27c2"
      },
      "source": [
        "train_sequence."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.data_sequence at 0x7f92f006d650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdvyGOpnBR6Q"
      },
      "source": [
        "train_sequence = data_sequence(x_train,y_train,batch_size=16,target_dim=(224,224),n_classes=6,shuffle=False)\n",
        "feature,lable = train_sequence.__getitem__(0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Qm38XTBf5b"
      },
      "source": [
        "emotion_dict = {0: 'Angry',1: 'Fear', 2: 'Happy', 3: 'Sad', 4: 'Surprise', 5:'Neutral'}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS21WTK9EL1l",
        "outputId": "43dd1632-942e-44e0-8a2a-0e813df515fe"
      },
      "source": [
        "!pip install keras-vggface\n",
        "!pip install keras_applications\n",
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-vggface\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/7d/5f0319ebdc09ac1a2272364fa9583f5067b6f8aff93fbbf8835d81cbaad7/keras_vggface-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.19.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.4.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (7.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (3.13)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n",
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_2zFgjtEF7p",
        "outputId": "9a06c14f-2172-418b-d2fa-302710ec9d93"
      },
      "source": [
        "vggface = VGGFace(model='resnet50', include_top=False, input_shape = (224,224,3))\n",
        "vggface.trainable = False\n",
        "vggface.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 1s 0us/step\n",
            "Model: \"vggface_resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 23,561,152\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,561,152\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLWquPTkEKoO",
        "outputId": "90b5b35a-b5ca-4793-dae1-8e25ed82484e"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# model = Sequential([vggface,\n",
        "#                     Flatten(),\n",
        "#                     Dropout(0.5),\n",
        "#                     BatchNormalization(),\n",
        "#                     Dense(128, activation='relu'),\n",
        "#                     Dropout(0.5),\n",
        "#                     BatchNormalization(),\n",
        "#                     Dense(len(emotion_dict), activation='softmax', name = 'classifer')])\n",
        "model = Sequential([vggface,\n",
        "                    Flatten(),\n",
        "                    Dropout(0.25),\n",
        "                    Dense(2048, activation='relu'),\n",
        "                    Dropout(0.25),\n",
        "                    Dense(1024, activation='relu'),\n",
        "                    Dense(6, activation='softmax', name = 'classifer')])\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vggface_resnet50 (Functional (None, 1, 1, 2048)        23561152  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "classifer (Dense)            (None, 6)                 6150      \n",
            "=================================================================\n",
            "Total params: 29,861,830\n",
            "Trainable params: 6,300,678\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGa11LWgEopS"
      },
      "source": [
        "train_sequence = data_sequence(x_train,y_train,batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.07)\n",
        "val_sequence   = data_sequence(x_val,  y_val,  batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\n",
        "test_sequence  = data_sequence(x_test, y_test, batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\n",
        "\n",
        "#train_sequence = data_sequence(x_train,y_train,batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.07)\n",
        "#val_sequence   = data_sequence(x_val,  y_val,  batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\n",
        "#test_sequence  = data_sequence(x_test, y_test, batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0avPy4szExop",
        "outputId": "7f6f9599-f54b-48d4-a18b-f01ad2120717"
      },
      "source": [
        "EPOCHS=100\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "\n",
        "model.compile(optimizer = Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0.00005,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "]\n",
        "\n",
        "hist = model.fit_generator(generator = train_sequence,\n",
        "                           validation_data = val_sequence,\n",
        "                           callbacks=callbacks,\n",
        "                           epochs = EPOCHS)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "676/676 [==============================] - 161s 186ms/step - loss: 1.9829 - accuracy: 0.4676 - val_loss: 1.0492 - val_accuracy: 0.5921\n",
            "Epoch 2/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.9875 - accuracy: 0.6292 - val_loss: 1.0125 - val_accuracy: 0.6130\n",
            "Epoch 3/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.8551 - accuracy: 0.6778 - val_loss: 0.9763 - val_accuracy: 0.6409\n",
            "Epoch 4/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.7426 - accuracy: 0.7234 - val_loss: 1.0502 - val_accuracy: 0.6211\n",
            "Epoch 5/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.6479 - accuracy: 0.7610 - val_loss: 1.0127 - val_accuracy: 0.6515\n",
            "Epoch 6/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.5859 - accuracy: 0.7871 - val_loss: 1.0297 - val_accuracy: 0.6551\n",
            "Epoch 7/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.5100 - accuracy: 0.8187 - val_loss: 1.0506 - val_accuracy: 0.6532\n",
            "Epoch 8/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.4717 - accuracy: 0.8289 - val_loss: 1.0522 - val_accuracy: 0.6590\n",
            "Epoch 9/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.4306 - accuracy: 0.8485 - val_loss: 1.1030 - val_accuracy: 0.6507\n",
            "Epoch 10/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.3960 - accuracy: 0.8621 - val_loss: 1.1083 - val_accuracy: 0.6602\n",
            "Epoch 11/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.3680 - accuracy: 0.8700 - val_loss: 1.1323 - val_accuracy: 0.6646\n",
            "Epoch 12/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.3442 - accuracy: 0.8795 - val_loss: 1.2138 - val_accuracy: 0.6535\n",
            "Epoch 13/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.3304 - accuracy: 0.8823 - val_loss: 1.1780 - val_accuracy: 0.6576\n",
            "Epoch 14/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.3142 - accuracy: 0.8907 - val_loss: 1.2056 - val_accuracy: 0.6643\n",
            "Epoch 15/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.2913 - accuracy: 0.8975 - val_loss: 1.2380 - val_accuracy: 0.6669\n",
            "Epoch 16/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.2916 - accuracy: 0.8986 - val_loss: 1.2396 - val_accuracy: 0.6571\n",
            "Epoch 17/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.2725 - accuracy: 0.9056 - val_loss: 1.2733 - val_accuracy: 0.6582\n",
            "Epoch 18/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.2611 - accuracy: 0.9092 - val_loss: 1.3186 - val_accuracy: 0.6618\n",
            "Epoch 19/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.2582 - accuracy: 0.9112 - val_loss: 1.3166 - val_accuracy: 0.6621\n",
            "Epoch 20/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.2504 - accuracy: 0.9164 - val_loss: 1.3329 - val_accuracy: 0.6568\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 21/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.2006 - accuracy: 0.9303 - val_loss: 1.4671 - val_accuracy: 0.6616\n",
            "Epoch 22/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1589 - accuracy: 0.9437 - val_loss: 1.5158 - val_accuracy: 0.6671\n",
            "Epoch 23/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1504 - accuracy: 0.9474 - val_loss: 1.5002 - val_accuracy: 0.6666\n",
            "Epoch 24/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1349 - accuracy: 0.9511 - val_loss: 1.4978 - val_accuracy: 0.6716\n",
            "Epoch 25/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1378 - accuracy: 0.9518 - val_loss: 1.5208 - val_accuracy: 0.6666\n",
            "Epoch 26/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1366 - accuracy: 0.9520 - val_loss: 1.5091 - val_accuracy: 0.6680\n",
            "Epoch 27/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1224 - accuracy: 0.9565 - val_loss: 1.5507 - val_accuracy: 0.6655\n",
            "Epoch 28/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1304 - accuracy: 0.9551 - val_loss: 1.6370 - val_accuracy: 0.6627\n",
            "Epoch 29/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1233 - accuracy: 0.9580 - val_loss: 1.6191 - val_accuracy: 0.6710\n",
            "\n",
            "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 30/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.1077 - accuracy: 0.9638 - val_loss: 1.6412 - val_accuracy: 0.6727\n",
            "Epoch 31/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0873 - accuracy: 0.9702 - val_loss: 1.7387 - val_accuracy: 0.6680\n",
            "Epoch 32/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0871 - accuracy: 0.9686 - val_loss: 1.7370 - val_accuracy: 0.6708\n",
            "Epoch 33/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0810 - accuracy: 0.9721 - val_loss: 1.7063 - val_accuracy: 0.6755\n",
            "Epoch 34/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0814 - accuracy: 0.9716 - val_loss: 1.7814 - val_accuracy: 0.6694\n",
            "Epoch 35/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0814 - accuracy: 0.9718 - val_loss: 1.7826 - val_accuracy: 0.6744\n",
            "Epoch 36/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0815 - accuracy: 0.9707 - val_loss: 1.7635 - val_accuracy: 0.6758\n",
            "Epoch 37/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0741 - accuracy: 0.9743 - val_loss: 1.8046 - val_accuracy: 0.6722\n",
            "Epoch 38/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0733 - accuracy: 0.9741 - val_loss: 1.8055 - val_accuracy: 0.6696\n",
            "Epoch 39/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0736 - accuracy: 0.9745 - val_loss: 1.8096 - val_accuracy: 0.6733\n",
            "Epoch 40/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0721 - accuracy: 0.9739 - val_loss: 1.8534 - val_accuracy: 0.6730\n",
            "Epoch 41/100\n",
            "676/676 [==============================] - 126s 186ms/step - loss: 0.0747 - accuracy: 0.9740 - val_loss: 1.8104 - val_accuracy: 0.6772\n",
            "Epoch 42/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0690 - accuracy: 0.9759 - val_loss: 1.8209 - val_accuracy: 0.6735\n",
            "Epoch 43/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0721 - accuracy: 0.9745 - val_loss: 1.8892 - val_accuracy: 0.6716\n",
            "Epoch 44/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0703 - accuracy: 0.9741 - val_loss: 1.7628 - val_accuracy: 0.6716\n",
            "Epoch 45/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0673 - accuracy: 0.9767 - val_loss: 1.8768 - val_accuracy: 0.6660\n",
            "Epoch 46/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0669 - accuracy: 0.9761 - val_loss: 1.8441 - val_accuracy: 0.6621\n",
            "\n",
            "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 47/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0620 - accuracy: 0.9789 - val_loss: 1.9211 - val_accuracy: 0.6694\n",
            "Epoch 48/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0573 - accuracy: 0.9795 - val_loss: 1.9190 - val_accuracy: 0.6671\n",
            "Epoch 49/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0551 - accuracy: 0.9799 - val_loss: 1.9464 - val_accuracy: 0.6735\n",
            "Epoch 50/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0567 - accuracy: 0.9801 - val_loss: 1.9403 - val_accuracy: 0.6710\n",
            "Epoch 51/100\n",
            "676/676 [==============================] - 126s 187ms/step - loss: 0.0529 - accuracy: 0.9813 - val_loss: 1.9487 - val_accuracy: 0.6719\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00051: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 00051: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqCCaS7QMdOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1925367c-89c3-456a-80ed-c577261b4780"
      },
      "source": [
        "model.evaluate(test_sequence)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 10s 172ms/step - loss: 1.5496 - accuracy: 0.6945\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5495702028274536, 0.6944754719734192]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9q4DZqeQr72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "02932443-ba7a-462e-be95-24c78a51d7c5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3zU9f3A8df7LossCCGEEUaYgsoMKKIiLtQqbsW9Kq7WUbXV/tpqrbV2WrW2ittWwa24xYGoCBIUkL2RgEIIBDLIuNz798fnGzjggAC5XHJ5Px+P7+PuvuPu/dVw7/tsUVWMMcaYnfmiHYAxxpjGyRKEMcaYsCxBGGOMCcsShDHGmLAsQRhjjAnLEoQxxpiwLEEYUw9E5BkRubeO564UkeMP9H2MiTRLEMYYY8KyBGGMMSYsSxCm2fCqdm4XkTkiUiYiT4pItoi8JyIlIvKRiGSEnD9aROaJSLGITBaRPiHHBorIN951LwJJO33WqSIyy7t2qoj028+YrxaRpSKyUUQmikgHb7+IyAMisl5EtojIdyJyiHfsFBGZ78W2RkRu26//YKbZswRhmpuzgROAXsBpwHvAr4Es3L+HGwFEpBcwHrjZO/Yu8JaIJIhIAvAG8F+gNfCy97541w4EngKuATKBx4CJIpK4L4GKyLHAn4DzgPbAKmCCd/hE4GjvPlp65xR5x54ErlHVNOAQ4JN9+VxjalmCMM3Nw6q6TlXXAJ8D01X1W1WtAF4HBnrnnQ+8o6qTVLUa+BvQAjgCOByIB/6pqtWq+gowI+QzxgKPqep0Va1R1WeBSu+6fXER8JSqfqOqlcCdwDAR6QpUA2nAQYCo6gJV/cG7rhroKyLpqrpJVb/Zx881BrAEYZqfdSHPt4Z5neo974D7xQ6AqgaB1UBH79ga3XGmy1Uhz7sAt3rVS8UiUgx08q7bFzvHUIorJXRU1U+AfwGPAOtFZJyIpHunng2cAqwSkc9EZNg+fq4xgCUIY3ZnLe6LHnB1/rgv+TXAD0BHb1+tziHPVwN/VNVWIVuyqo4/wBhScFVWawBU9SFVHQz0xVU13e7tn6GqpwNtcVVhL+3j5xoDWIIwZndeAn4iIseJSDxwK66aaCrwFRAAbhSReBE5Cxgacu3jwLUicpjXmJwiIj8RkbR9jGE8cIWIDPDaL+7DVYmtFJEh3vvHA2VABRD02kguEpGWXtXYFiB4AP8dTDNmCcKYMFR1EXAx8DCwAdegfZqqVqlqFXAWcDmwEdde8VrItfnA1bgqoE3AUu/cfY3hI+C3wKu4Ukt3YIx3OB2XiDbhqqGKgL96xy4BVorIFuBaXFuGMftMbMEgY4wx4VgJwhhjTFiWIIwxxoRlCcIYY0xYliCMMcaEFRftAOpTmzZttGvXrtEOwxhjmoyZM2duUNWscMdiKkF07dqV/Pz8aIdhjDFNhois2t2xiFUxiUgnEfnUm1VynojcFOYcEZGHvNkq54jIoJBjl4nIEm+7LFJxGmOMCS+SJYgAcKuqfuONIJ0pIpNUdX7IOScDPb3tMOA/wGEi0hq4C8gD1Lt2oqpuimC8xhhjQkSsBKGqP9TOIqmqJcAC3ERnoU4HnlNnGtBKRNoDo4BJqrrRSwqTgJMiFasxxphdNUgbhDc98UBg+k6HOuImNqtV4O3b3f5w7z0WN70ynTt33uV4dXU1BQUFVFRU7F/wTURSUhI5OTnEx8dHOxRjTIyIeIIQkVTcXDI3q+qW+n5/VR0HjAPIy8vbZd6QgoIC0tLS6Nq1KztOvhk7VJWioiIKCgrIzc2NdjjGmBgR0XEQ3kyTrwLPq+prYU5Zg5tCuVaOt293+/dZRUUFmZmZMZscAESEzMzMmC8lGWMaViR7MQlu6cMFqvqP3Zw2EbjU6810OLDZWxXrA+BEEcnw1gg+0du3v7Hs76VNRnO4R2NMw4pkFdNw3LTD34nILG/fr/EWVlHVR3Hr/J6Cmw65HLjCO7ZRRP7A9mUc71HVjRGM1RhjGofi76HkR0hrD2ntwB+mXbEmAJu/h6LlsHE5VJfBkbfUeygRSxCq+gWwx5+13pKNN+zm2FO4hd+btOLiYl544QWuv/76fbrulFNO4YUXXqBVq1YRiswY06j8MBu++CfMfwO0do0ngZQslyjSO4AqbFwGm1ZBsHr7tantYPjNUM81CTE1kroxKi4u5t///vcuCSIQCBAXt/v//O+++26kQzPGRJsqrPoSvngAln4ECWlwxM+hy3Ao+QG2/OAeS36AzV4zbPbB0Gc0tO4Gmd2hdXdIbVvvyQEsQUTcHXfcwbJlyxgwYADx8fEkJSWRkZHBwoULWbx4MWeccQarV6+moqKCm266ibFjxwLbpw0pLS3l5JNP5sgjj2Tq1Kl07NiRN998kxYtWkT5zowxe6UKUx+GDYsgPhnikiC+hdt88a60UDDDlRKO+x3kXQUtGk+tQbNKEL9/ax7z19ZvT9u+HdK567SDd3v8/vvvZ+7cucyaNYvJkyfzk5/8hLlz527rjvrUU0/RunVrtm7dypAhQzj77LPJzMzc4T2WLFnC+PHjefzxxznvvPN49dVXufjii+v1PowxETD9MZj0W0hp66qEqrdCIKS3YavOcMrfYODFLmk0Ms0qQTQGQ4cO3WGswkMPPcTrr78OwOrVq1myZMkuCSI3N5cBAwYAMHjwYFauXNlg8Rpj9lNBPnz4G+h1MlwwfnsVUDDokkSgApJags8f3Tj3oFkliD390m8oKSkp255PnjyZjz76iK+++ork5GSOOeaYsGMZEhMTtz33+/1s3bq1QWI1JuYFa6BwEWT3rd/3Ld8IL18O6e3hzP/s2D7g80FCstsaOVswKMLS0tIoKSkJe2zz5s1kZGSQnJzMwoULmTZtWgNHZ0wzpgrv3g7/GQYL36m/9w0G4Y3rXFfVc5+BFhn1994NzBJEhGVmZjJ8+HAOOeQQbr/99h2OnXTSSQQCAfr06cMdd9zB4YcfHqUojWmGpv0H8p8EX5zrRaS7zNSzq+LV8PeD4NWfuufhTH0IFr8Po+6DjoPrN+YGJlqX/yhNRF5enu68YNCCBQvo06dPlCJqWM3pXo05IAvfhQkXQp9ToetR8N4v4Yr3ocuwPV838ecwa7xrN1CFYTe4AWpJ6e74yi/h2dOgz2mu9NAEZjgQkZmqmhfumJUgjDFNz6qprgRQU733c3e2dha8ehV0GABnjoOBl0CL1vDlP/d83cbl8O3zkHcl/HwmHHwGfPEPeHgQ5D/lxiy8ciVkdIHRDzeJ5LA3liCMMU1HsAY++ws88xN4/w54+mQ3qriuNq+B8WNcQrhgwvbG4sOucdVC6xfs/trP/uKmvTjqF9AyB84aB1d/Apk94e1b4KEBUFEM5z23vUTRxFmCMMY0DaXr4X9nwad/hEPPhTMedT2QHjsK5r+59+srS2H8+e7xopfc9BW1ho51A9mmPhz+2sLFMOdFGPLTHa/rOBiueBfO+y+07etKDu0OPbD7bEQsQRhjGr8Vn8OjR8L309yX8JmPwYAL4JopbqqJly6Ft38B1buZ8r6yxFUrrZvv2gayd+ryntzaVTXNeWn7lBahPrsf4lqEnxBPBPqOhrGfQr/zDvhWG5NmNQ7CGNPEBGvg83/A5PtcIrjk9R2/3FvnwpUfwMe/h6/+Baunw8l/gfIiWDcX1s1zj5tWuvN/8nfoeXz4zxp2A8x4Aqb/B068d/v+dfNh7msuOaS0iditNkaWIIwxDWfRe27W0mAgZKtxjc3V5bC1GLZucluF9zxQAYeeB6c+AImpu75nXAKM+iPkjoA3roVnTnH7xeeSSvsBbiqLTodB7tG7jy2jCxx8JuQ/A0fdtn1OpMn3QaI3iV4zYwmigd19992kpqZy2223RTsUYxrO1mJ49zb47mX3Wnxu/MG2ze/aAFpkuC2z+/bnHQdD39P33iuo14lw3VRXHZXZDbL67Pto5eE3wtxXXK+ko37hktmCt2DEHa4aqpmxBGGM2btApavHr6nytoB7DAYgs8eev4hXfA6vX+umrB75Gzjy5vCL4NSHtHbQ79z9v759f+g2EqY/CodfD5/eB0mtYNi+recSKyxBNIA//vGPPPvss7Rt25ZOnToxePBgli1bxg033EBhYSHJyck8/vjjtG/fnn79+rFixQp8Ph9lZWUcdNBBLF++nPj4CP2DMmZv1s2Dp09xVT7hxCdDzxPcr/yeo7ZXAwUqXY+jLx9yaxdcNQlymsDI4uE3wX/PcIPnFr8Px/7WTarXDEUsQYjIU8CpwHpVPSTM8duBi0Li6ANkecuNrgRKgBogsLtRfvvsvTvgx+/q5a22aXconHz/bg/PnDmTCRMmMGvWLAKBAIMGDWLw4MGMHTuWRx99lJ49ezJ9+nSuv/56PvnkEwYMGMBnn33GyJEjefvttxk1apQlBxM9FZvhxYvdOgan/M398vcnuLUM/PGAwsovXDXM/DfdeT2Od1v+k+7f2+ArXBtBQspeP65R6HaMK0l88ywkZ8Jh10Y7oqiJZAniGeBfwHPhDqrqX4G/AojIacAtO607PVJVN0Qwvgbx+eefc+aZZ5Kc7Irgo0ePpqKigqlTp3LuuduLwpWVlQCcf/75vPjii4wcOZIJEybs81KlxtQbVXjjerdG8uXvQOfdzBV28Jmu59Dq6S5JzJ8IC9+G5DZuMFrvkxs27gMl4koRr1zplvEM1zDeTERyTeopItK1jqdfAIyPVCzb7OGXfkMKBoO0atWKWbNm7XJs9OjR/PrXv2bjxo3MnDmTY489NgoRGoObemLh23DS/btPDrV8fuhyhNtG/cl1LW2Z03Qbdg8+y7U95I6IdiRRFfWBciKSDJwEvBqyW4EPRWSmiIzdy/VjRSRfRPILCwsjGep+Ofroo3njjTfYunUrJSUlvPXWWyQnJ5Obm8vLL7seHarK7NmzAUhNTWXIkCHcdNNNnHrqqfj9jXcxEdPIla6H938N79zqHj+6Gybf78YVzHjCrVmwO8s/g4/vcV+U+1rF4vNB+35NNzmAK0X0OA78zbuZtjHc/WnAlztVLx2pqmtEpC0wSUQWquqUcBer6jhgHLjZXCMf7r4ZNGgQ559/Pv3796dt27YMGTIEgOeff57rrruOe++9l+rqasaMGUP//v0BV8107rnnMnny5ChGbpq8t29x4w6SWroeR4FKt+xlrY9+D0fcCIdft2M1yuY1rnols2fMTDpn9k9Ep/v2qpjeDtdIHXLO68DLqvrCbo7fDZSq6t/29nk23XfzuVezF0s+gufPhuPucv35awWDUFMJRUvh0z/BoncgJcsNDMu7AhA30Gz9Arj6U8jqFbVbMA2j0U73LSItgRHAmyH7UkQkrfY5cCIwNzoRGtMEBSrhvdvd+IRhP9vxmM8H8S1c77sLXoCrPoKsg+D9X8HDea7HUsEMOP0RSw4mot1cxwPHAG1EpAC4C4gHUNVHvdPOBD5U1bKQS7OB18UVa+OAF1T1/UjFaUzMmfqwW7vg4tfcNBR70mkIXPYWLJ/s2hyWfOCSysFnNEiopnGLZC+mC+pwzjO47rCh+5YD/es5FiTG61FjaWVAcwCKV8OUv0Gf0a6RtS5EoPtI1/9/3Tw3bbUxNIJeTJGWlJREUVFRTH+BqipFRUUkJSVFOxQTbR/c6b7wR92379eKQLtDXDWUMTSOXkwRlZOTQ0FBAY2xC2x9SkpKIicnJ9phmGha+rEb0Xzsb6FVp2hHY2JAzCeI+Ph4cnNzox2GMZEVqHRzB7Xu3iynpTaREfMJwphm4at/ua6rF78KcYnRjsbECKtsNKapK5jpGqYPOtVNkmdMPbEShDGNzXu/cmsj9zwBep/ieiMlpu14TlkRfPcSfPs8rPvOjZY+6U/RidfELEsQxjQmSz5yi9V0GARLPoQ5L7rptXOPdrOipmbD7Amw+AM3bUaHgW4a7kPObtpzH5lGyRKEMY3F1mKY+HM3svmK99xSnKunw6J33fbOre68lCw47BoYcBFk25gFEzmWIIxpLN6/A0rXwZjnId4b09J1uNtOvBc2LHbLdnYZHrklO40JYQnCmMZg4bswezwcfTt0HLTrcRHI6u02YxqI9WIyJtrKN8JbN0H2oXD0L6MdjTHbWAnCmGh751bYugkuqcPkesY0ICtBGBNNc1+Dea/BMb9yU3Ab04hYgjAmWkrXu9JDh0Ew/JZoR2PMLixBGBMNm1bC+DFQVQZnPtrs1z42jZP9VRrTkFTdKOl3bnU9k85+wnommUbLEoQxDWVrsUsMc1+BzsPgzMcgo0u0ozJmtyK55OhTwKnAelU9JMzxY3BrUa/wdr2mqvd4x04CHgT8wBOqen+k4jTNnCqs+AxS27lf8vuz8mDFFvjuZTeOQYPQfgB0GOAe2/Zxg9pWfQWvjYUta2Dkb+CoX4DPX//3Y0w9imQJ4hngX8Bzezjnc1U9NXSHiPiBR4ATgAJghohMVNX5kQrUNFNV5fDm9TDvdfc6tZ1bdrPbMdBtBKR32P21qrD6a/jmWXd9dTlkHwItMlyyyH/SnedPdIln3Vxo1Rmu+hBy8iJ7X8bUk0iuST1FRLrux6VDgaXe2tSIyATgdMAShKk/W9bChAth7Sz3iz61LSyfDEsnwZwJ7pw2vaBlDsQnQ0IKxLeA+BT3y3/Jh1C4EBJS4dBzYfBlrjeSCASDsGkFrP3WbT/Mhrwr4fi7d52V1ZhGLNptEMNEZDawFrhNVecBHYHVIecUAIft7g1EZCwwFqBz584RDNXEjDXfuORQsQXGvAAHneL2D77Mfbmvm+uSxcovoHwDlPzoehtVl0P1VvfYYSCc9hAcctauX/o+H2R2d9uh5zT47RlTX6KZIL4BuqhqqYicArwB9NzXN1HVccA4gLy8PK3fEE3MmfsavHE9pLRx1T3tdmoe8/mgfT+3Db8x/Huo7l9bhTFNTNTGQajqFlUt9Z6/C8SLSBtgDRC64nqOt8+Y/acKk/8Mr1zhvvyv/mTX5FBXlhxMMxG1BCEi7UTcvzQRGerFUgTMAHqKSK6IJABjgInRitPEiMUfwOT7oN8YuOwt1+ZgjNmjSHZzHQ8cA7QRkQLgLiAeQFUfBc4BrhORALAVGKOqCgRE5GfAB7hurk95bRPG7L9pj0B6Rzj9X7aWgjF1FMleTBfs5fi/cN1gwx17F3g3EnGZZmjdPFgxBY67y5KDMfvA5mIysW/6oxDXAgZfHu1IjGlSLEGY2FZW5OY+6n8+JLeOdjTGNCmWIExsm/k0BCrgsOuiHYkxTY4lCBO7aqphxhPQbSS0PSja0RjT5FiCMLFr/ptQ8gMcbqUHY/aHJQgTu6b9B1p3hx4nRDsSY5okSxAmNq2eAWvy4bBr3fQZxph9Zv9yTGya/h9IbAkDLox2JMY0WZYgTOzZvAbmvQGDLoHE1GhHY0yTZQnCxJ4ZTwAKQ6+OdiTGNGmWIExsKV3vxj70PgUyukY7GmOatGgvGGTMgakJQMEMWPoRLPvYrRAHMOxn0Y3LmBjQ7BNETVDJX7mRzNQEerS15SAbFVXIfwq+/S/44iEu0S37GZfktqoyWPk5VG4B8UPOEBj5a+h1klvzwRhzQJp9ghDgsqe/5sKhXfjdaX2jHY6pVVUGb98Cc16E9v3dmtCBCigrhOoKCGwFXxwcfCb0OA5yR0CLVtGO2piY0uwThM8n9MpOY/G6kmiHYmptWAovXQLrF8DI/4OjbrOxDMZEQbNPEAC9stP4bHFhtMMwAAvecmtG++Lg4ldd6cAYExX2swzonZ1GYUklG8uqoh1K81UTgEm/gxcvhswecM0USw7GRFnEEoSIPCUi60Vk7m6OXyQic0TkOxGZKiL9Q46t9PbPEpH8SMVYq1c71zht1UxRsmoqPD4SvnwQ8q6CK9+HVp2iHZUxzV4kSxDPACft4fgKYISqHgr8ARi30/GRqjpAVfMiFN82vbMtQURF8Wp4+Qp4+mQoL4Jzn4FT/+F6Kxljoi6Sa1JPEZGuezg+NeTlNCAnUrHsTXZ6IulJcSz60RJEg6gqd6WFL//pXo+4A4bfBAnJ0Y3LGLODxtJIfRXwXshrBT4UEQUeU9WdSxfbiMhYYCxA586d9+vDRYTe7awnU70qmAlrZkJNJQQqoabKPQYqXUP0lgI4+Cw44R6rTjKmkYp6ghCRkbgEcWTI7iNVdY2ItAUmichCVZ0S7noveYwDyMvL0/2No1d2Gm/NXouqIiL7+zamaBl8dJdLAjvzJ4A/EbJ6w9mPQ5cjGj4+Y0ydRTVBiEg/4AngZFUtqt2vqmu8x/Ui8jowFAibIOpL73ZpPD89wLotlbRrmRTJj4pNZUXw2Z8h/0mXBEb+BgZd6o18TnTJwRKvMU1K1BKEiHQGXgMuUdXFIftTAJ+qlnjPTwTuiXQ8vbyG6kXrSppvgqjYAi9eBNmHwDF3QlL63q+proDpj8Lnf4eqUhh0mbs2LTvy8RpjIipiCUJExgPHAG1EpAC4C4gHUNVHgd8BmcC/vSqdgNdjKRt43dsXB7ygqu9HKs5atQli8Y8ljOiVFemPa5ze+yWs/AJWfA7zXodR97mpLML98q8shZnPwFePQMlaN//R8b+Htgc1eNjGmMiIZC+mC/Zy/KfAT8PsXw703/WKyGqdkkBWWiKLmmtD9XevwOzxrkdRrxPdPEivXOEmyjvlb5DZ3Z1XvhGmPwZfPwZbN0HXo+CsxyD36OjGb4ypd1FvpG5MejfXOZk2rXIJodNhcPTt4I+Dqz91C+98ci/8exgcebObQC//aaguc+stHPkL6DQk2tEbYyLEEkSIXtlpvPD1KoJBxedrJg2qNQF4bax7ftY4lxwAfH447Broezp88GvXAC1+OPQcGH4zZNvMt8bEOksQIXq3S6WiOsjqTeV0yUyJdjgN4/O/w+ppcNbj4VdgS2sH5zwFR94CiemQ0aXBQzTGRIdN1hdiW0+m5jKievXXrmRw6HnQ77w9n9vuUEsOxjQzliBC9GxOczJVbIFXfwotc+Anf4t2NMaYRsiqmEKkJsaRk9GCRetKox1KZFWVw9s3w+YCN3NqUstoR2SMaYQsQeykd3Yai2O1iqlwMcx8GmY9DxWb4djfQKeh0Y7KGNNIWYLYSa92bnW5qkCQhLgYqIGrqYaFb8OMJ2Hl5+CLh76j3boLNheSMWYPLEHspHd2GoGgsrKobFujdaNXE4DF78Pm1VC6HsrWu8fS9VC8yg1oa9kZjvsdDLwEUttGO2JjTBNgCWInvdtt78nUJBJEZakb8bzkQ/faFwcpWS4JpLSFdodAn9HQ43g3tsEYY+rIEsROumWl4PdJ0+jJtOUHeOE8WDfPTYdxyNmQ1Ap8MVA1ZoyJOksQO0mM85PbJqXxj4VYNx+eP9dVH134IvQ8IdoRGWNijCWIMHpnpzFv7eZoh7F7yyfDi5dAfDJc+R60b/C5DY0xzYDVRQDojgvR9cpOY9XGcrZW1UQpoN2oCcCsF+B/Z0N6R/jpR5YcjDERU6cShIjcBDwNlOBWgBsI3KGqH0YwtoYRDML4Ma6KJu9K8Pnp3S4VVVi6vpRDc/ZhENnkP0PRErfOcnqH/YilBlZMgTkvwaovIVDhbVVubWcNuvNyR8D5/7UBbsaYiKprFdOVqvqgiIwCMoBLgP8CTT9BVG5xX77v3gazJ8BpD9IruyvgVperc4KYPQEm3wcILP4ATvg9DLp87w3GqvDjHJcUvnsFSn90k+J1P9YlgNrlOuMSIS4JUtrAgIshLuFA7toYY/aqrgmidu7rU4D/quo8kRhZYLhFK7jkDfcF/cGdMG4EXYf9nLS4gXXvyfTDbHjrJrd4zqkPwDu/cOsrfPcKnPYgtOm54/nBGljzjeuaumAiFC50A9h6jYJDz3Wrs8U302VPjTGNRl0TxEwR+RDIBe4UkTQguLeLROQp4FRgvaoeEua4AA/iEk85cLmqfuMduwz4jXfqvar6bB1j3Xci0P98V8304W/xffkAHya0478rbgb67Pna8o3w4sXQojWc8zSkZsGlE+Hb/8GH/wf/GQ4jfgmDLnXVR0s+hKUfQXkRiA86D4NT/+nWXUhuHbFbNMaYfSW6UwNt2JNEfMAAYLmqFotIayBHVefs5bqjgVLgud0kiFOAn+MSxGHAg6p6mPf++UAeoMBMYLCqbtrT5+Xl5Wl+fv5e72evVnzO+vHX0bZqtftFP+q+8KOPgzXw/DluHecr3oOcvB2Pl6xz6zzPf2P7vuRM6HGCS0Y9joMWGQcerzHG7CcRmamqeeGO1bUEMQyYpaplInIxMAj3y3+PVHWKiHTdwymn45KHAtNEpJWItAeOASap6kbvBiYBJwHj6xjvgck9ijcPf4nyT/7KjfPfRJZ8CMffvWubwqd/hGWfuGqknZMDQFo2nPesa5P4cQ50GwkdBtqIZmNMk1DXbq7/AcpFpD9wK7AMeK4ePr8jsDrkdYG3b3f7dyEiY0UkX0TyCwsL6yEkp0eHNjwQOIe5o9+Fdv1cm8JTJ8KPc90JC95yq7ENuhQGX77nN+s1yq31nJNnycEY02TUNUEEvF/5pwP/UtVHgEYxUZGqjlPVPFXNy8rKqrf37eXNyTSnoi1c9hac+RhsXAGPHQ3v3AqvXwcdB7spLowxJgbVNUGUiMiduO6t73htEvH18PlrgE4hr3O8fbvb32A6tEwiNTGOuWu2eI3YY+BnM2DgRTDjCdft9Lzn3KMxxsSguiaI84FK3HiIH3Ff2H+th8+fCFwqzuHAZlX9AfgAOFFEMkQkAzjR29dgRISRB7Xl7dlr2VJR7XYmt4bRD8M1U+DKD9xyncYYE6PqlCC8pPA80FJETgUqVHWvbRAiMh74CugtIgUicpWIXCsi13qnvAssB5YCjwPXe5+3EfgDMMPb7qltsG5IY4/qRkllgPHTv9/xQPv+0KZHQ4djjDENqq7dXM/DlRgm4wbNHQXcrqqvRDS6fVRv3VxDXPj4NJYVlvL5L4+NjRXmjDEmxJ66udb1G+//gCGqepmqXgoMBX5bXwE2ZteM6M66LZW8OatBm0CMMSbq6pogfKq6PuR10T5c26Qd3bMNB7VL4/HPl1OX0pYxxsSKun7Jvy8iHzhhHEgAABigSURBVIjI5SJyOfAOrv0g5okI14zoxuJ1pUxeVH/jLIwxprGrayP17cA4oJ+3jVPVX0UysMbk1H4d6NAyiUc/WxbtUIwxpsHUeUU5VX0VeDWCsTRa8X4fVx6Zy73vLGDW6mIGdGoV7ZCMMSbi9liCEJESEdkSZisRkS0NFWRjMGZoZ9KS4hg3xUoRxpjmYY8JQlXTVDU9zJamqukNFWRjkJoYxyWHd+H9uT+yckNZtMMxxpiIaxY9kerL5Ud0Jc7n44kvlkc7FGOMiThLEPugbXoSZw3qyMv5BRSVVkY7HGOMiShLEPvop0d1ozIQ5NmpK6MdijHGRJQliH3Uo20qJx/Sjie+WMG6LRXRDscYYyLGEsR+uPPkPgSCyp/fWxjtUIwxJmIsQeyHzpnJXH1ULq99u4aZq/a4TLYxxjRZliD20/XH9CA7PZHfvzWPYNDmaDLGxB5LEPspJTGOO0/uw5yCzbwysyDa4RhjTL2zBHEATh/QgcFdMvjLBwu3rzpnjDExwhLEARAR7j7tYIrKqnjooyXRDscYY+pVRBOEiJwkIotEZKmI3BHm+AMiMsvbFotIccixmpBjEyMZ54E4NKcl5+d14pmpK1m6vjTa4RhjTL2JWIIQET/wCHAy0Be4QET6hp6jqreo6gBVHQA8DLwWcnhr7TFVHR2pOOvDbaN60yLBzz1vz7dFhYwxMSOSJYihwFJVXa6qVcAE4PQ9nH8BMD6C8URMm9REbjquJ1MWF/LxgvV7v8AYY5qASCaIjsDqkNcF3r5diEgXIBf4JGR3kojki8g0ETljdx8iImO98/ILC6O34ttlR3Sle1YKd781j7LKQNTiMMaY+tJYGqnHAK+oak3Ivi6qmgdcCPxTRLqHu1BVx6lqnqrmZWVlNUSsYcX7fdx/dj/WFG/lvncXRC0OY4ypL5FMEGuATiGvc7x94Yxhp+olVV3jPS4HJgMD6z/E+jWka2uuGp7L89O/Z8piW7/aGNO0RTJBzAB6ikiuiCTgksAuvZFE5CAgA/gqZF+GiCR6z9sAw4H5EYy13tw2qjfds1L41atz2LzVxkYYY5quiCUIVQ0APwM+ABYAL6nqPBG5R0RCeyWNASbojt1/+gD5IjIb+BS4X1WbRIJIivfz9/MGsG5LBX94u0mEbIwxYUksdcvMy8vT/Pz8aIcBwF8/WMgjny7jiUvzOL5vdrTDMcaYsERkptfeu4vG0kgdc248ricHtUvjjte+Y1NZVbTDMcaYfWYJIkIS4/z8/bz+FJdX8buJ86IdjjHG7DNLEBF0cIeW3HhcT96avZZ35vwQ7XCMMWafWIKIsOuO6U6/nJbc+docFq8riXY4xhhTZ5YgIize7+ORCweRFO/n0ie/Zk3x1miHZIwxdWIJogF0ap3Ms1cOpawqwKVPTrdGa2NMk2AJooH0aZ/OE5fmsXrTVq54ZgblVTZfkzGmcbME0YAO65bJwxcMZE5BMTc8/w3VNcFoh2SMMbtlCaKBjTq4HfeecSifLirkV6/OsfUjjDGNVly0A2iOLjysMxtKK/nHpMVkpSVy58l9oh2SMcbswhJElPz82B5sKK3ksc+Wk5uZwpihnaMdkjHG7MCqmKJERPjdqX05ulcWv3ljLtOWF0U7JGOM2YEliCiK8/t4+IKBdM5M5rr/zWT1xvJoh2SMMdtYgoiyli3iefKyIQQVrnp2BiUVtoaEMaZxsATRCOS2SeHfFw1iWWEZN0+YRU3QejYZY6LPEkQjMbxHG+4+rS8fL1zPX95fGO1wjDHGejE1JpcM68qidSU8NmU5PbPTOGdwTrRDMsY0YxEtQYjISSKySESWisgdYY5fLiKFIjLL234acuwyEVnibZdFMs7G5K7TDuaI7pnc8eocHvl0qVU3GWOiJmIJQkT8wCPAyUBf4AIR6Rvm1BdVdYC3PeFd2xq4CzgMGArcJSIZkYq1MYn3+3j0ksGMOqQdf/1gEReMm2a9m4wxURHJEsRQYKmqLlfVKmACcHodrx0FTFLVjaq6CZgEnBShOBud9KR4/nXBQP5+bn/m/7CFUx78nNe/LbBpOYwxDSqSCaIjsDrkdYG3b2dni8gcEXlFRDrt47WIyFgRyReR/MLCwvqIu1EQEc4enMN7Nx1F73Zp3PLibG6cMIvN5dYN1hjTMKLdi+ktoKuq9sOVEp7d1zdQ1XGqmqeqeVlZWfUeYLR1ap3Mi9cM4/ZRvXnvux846cEpTJq/LtphGWOagUgmiDVAp5DXOd6+bVS1SFUrvZdPAIPrem1z4vcJN4zswavXHUFaUhxXP5fP1c/l2+p0xpiIimSCmAH0FJFcEUkAxgATQ08QkfYhL0cDC7znHwAnikiG1zh9orevWevfqRXv3HgUd5x8EJ8vKeT4v3/GuCnLbF0JY0xERCxBqGoA+Bnui30B8JKqzhORe0RktHfajSIyT0RmAzcCl3vXbgT+gEsyM4B7vH3NXrzfx7UjujPplhEc0T2T+95dyGkPf8HMVfafxxhTvySWesbk5eVpfn5+tMNoMKrKh/PX8fuJ81i7uYKzB+Xwq5N60zY9KdqhGWOaCBGZqap54Y5Fu5HaHAARYdTB7Zj0ixFcO6I7E2evYeTfJvPYZ8uoCli1kzHmwFiCiAEpiXHccfJBfHjLCA7vlsmf3lvIqH9O4ZOF1tvJGLP/LEHEkNw2KTx5+RCeuWIIInDlM/lc/vTXzFpdHO3QjDFNkLVBxKiqQJBnp67koU+WUFIRIK9LBlcdmcuJB7fD75Noh2eMaST21AZhCSLGlVRU83J+AU9PXcHqjVvJyWjB5Ud05fwhnUhLio92eMaYKLMEYagJKpPm/8iTX6xgxspNpCbGcdFhnbnqyFzr9WRMM2YJwuxgTkExT3y+grfnrCXO7+OcwTlce3R3OmcmRzs0Y0wDswRhwlpVVMZjU5bzSn4BgWCQ0/p34LpjunNQu/Roh2aMaSCWIMwerdtSwZNfrOD5aasoq6qhb/t0juieybDumQzJbU26tVUYE7MsQZg6KS6vYsKM1Xy2qJCZ32+iKhDEJ3Box5YM696G4/u0ZXCXDESsF5QxscIShNlnFdU1fPt9MV8t28BXy4uYtbqY6hqlS2YyZw3M4axBHenU2tosjGnqLEGYA1ZaGeD9uT/y6swCvlpeBMDQrq05e3BHTuzbjoyUhChHaIzZH5YgTL0q2FTOm7PW8urMApZvKAOgR9tU8rpkkNe1NXldMuiSmWxVUcY0AZYgTESoKrMLNvPl0g3MXLWJ/JUb2VIRAKBNaiIDOrWkV3Yavdul0Ss7jW5ZKSTG+aMctTEm1J4SRFxDB2Nih4gwoFMrBnRqBUAwqCwtLGXGyo3MXLmJuWs3M3lRIYGg+xHi9wm5bVI4pEM6R/Row/AebejYqkU0b8EYswdWgjARVRUIsmJDGYvWlbD4xxIW/ljCrNWb2FBaBbgJBof3yGR49zYMzW1NZmpilCM2pnmxEoSJmoQ4H73buWom+rt9qsqidSV8sWQDU5cV8fo3a/jftO8BaJ2SQPesFLpnpbqtbQpdM1PITk8iJdH+XI1pSBEtQYjIScCDgB94QlXv3+n4L4CfAgGgELhSVVd5x2qA77xTv1fV0eyFlSCapuqaILNXFzNrdTHLCktZtr6M5RtKt5UyaqUmxtE2PZHstCTapifSNi2RNqmJZKYmkpmaQJsU95iZmmBtHcbUUVRKECLiBx4BTgAKgBkiMlFV54ec9i2Qp6rlInId8BfgfO/YVlUdEKn4TOMR7/e53k9dW++wv7i8imWFZawqKmPdlkrWl1Swfksl67ZU8O33xazbUkFlmJXzUhL8PH3FUIbmtt7lmDGm7iJZZh8KLFXV5QAiMgE4HdiWIFT105DzpwEXRzAe08S0Sk5gcJcEBnfJCHtcVSmvqqGotIoNZZUUlVZRVFrJY1OW87MXvuHdm46ijbVpGLPfIrmiXEdgdcjrAm/f7lwFvBfyOklE8kVkmoicsbuLRGSsd15+YWHhgUVsmhQRISUxjs6ZyQzqnMEJfbMZM7Qz/75oEJu3VnPThG+pCcZOJwxjGlqjWHJURC4G8oC/huzu4tWLXQj8U0S6h7tWVcepap6q5mVlZTVAtKax69M+nT+cfghfLi3ioY+XRDscY5qsSCaINUCnkNc53r4diMjxwP8Bo1W1sna/qq7xHpcDk4GBEYzVxJhz83I4e1AOD32yhCmLrWRpzP6IZIKYAfQUkVwRSQDGABNDTxCRgcBjuOSwPmR/hogkes/bAMMJabswZm9EhHvPOIRebdO4+cVZ/LB5a7RDMqbJiViCUNUA8DPgA2AB8JKqzhORe0SktsvqX4FU4GURmSUitQmkD5AvIrOBT4H7d+r9ZMxetUjw88hFg6isruHnL3xLdc2uPZ6MMbtnI6lNzHtz1hpumjCLsUd349en9Il2OMY0KjaS2jRrpw/oyIyVGxk3ZTklFQFuOb4nbdOToh2WMY2eJQjTLPz21L7E+338b9oq3vh2DVcflcvYEd1Jtek7jNmtRtHN1ZhIS4zzc9dpB/PRL0ZwXJ+2PPTJUkb85VOenbqSqjCjsY0x1gZhmqnZq4u5790FTF+xkc6tkzk0pyUpCX6SE+JISXSPqYlxdM9K5dCOLWmZHB/tkI2JCGuDMGYn/Tu1YsLYw/l00XrGTVnOgh+2UF5ZQ1lVgPKqml1GYHfNTKZfTiv65bSkX04r2rdMIjUxjtSkOOL9VhA3sckShGm2RIRjD8rm2IOyd9ivqlQGgmypqGbxj6XMLijmu4LN5K/cyMTZa3d5n4Q4H2leskjw+/CJ4PMJfh/uuci2acx7tE11W1babkslNSELLBkTTZYgjNmJiJAU7ycp3k/btCSO7Nlm27HCkkrmrt3MhpJKSisDlFUGKKkMUFoRoLQyQHVNkJqgElS3wl5QlRqFtcVb+WLphh3aO9qkJtA6JYGK6iAV1TVsra6hsjpIVU0QEWjZIp7WyQlkpLjzWicn0KVNMmcNzKFdS+uFZSLP2iCMaSA1QaVgUznLCktZut5tm7dW08JLRknxflok+EmK8xNUZVN5FUVlVWwqq2Kjt60vqcTvE07ok83Fh3fhiO6Z+KykYQ6AtUEY0wj4fUKXzBS6ZKbsUq1VV6uKynhh+ve8lL+a9+f9SG6bFC46rDPnDM6hVXJCPUdsmjsrQRjTBFVU1/De3B/437TvmblqEyKQk9Fi+1KtWal0z0ohNyuF1skJxFlDutkNK0EYE2OS4v2cOTCHMwfmMH/tFibNX8fSwlKWrS9l2vIiKqp3HNuRlhhHq5R4WrVIoFVyPBnJCbRNS3RLuKYn0TYtiez0RNqkJVJTo2z12kS2VrnHiuoaUhPjaJPqlnltkWBLujYHliCMaeL6dkinb4f0ba+DQWXt5q3blmvdVFbNpvIqNm91j8Xl1awqKmd9ScUuiaSukhP8bv3vlERSEv0k+H3E+30kxLktMc5HYpyf5ITaLY7kBK+NJd5P4k7nJcT5tvXa2l6p4Z6IyLbzEuPdNQl+HyI7tr2ous4BsP89wGqCSlUgSFUgSCAYJL1FfLPuxmwJwpgY4/MJORnJ5GQkA7tfREtVKakMsH5LJeu3VLCupIINJVXE+YVk74u8hddwnhjnp7Symg2lVW6J19JKikorKSqrYmtVDSUVAffFWhPc9gVbWwIJRGhVv3i/uN5iquxcU+73ybYklOD3kRjvI97no0aVmqDbAkEl6D3Wxr7z+BcRyEhOICs1kaw0t2WmJOD3C4R8du1l2emJdMtKpVtWCp1bJzf55GIJwphmSkRIT4onPSmeHm1TI/Y5VYEg5d4AxPKqABXVQSq9JFJVE6SyumaXL+fa0oGw/Vd9pXduZcBdH6gJeuNMAO/RJ4IqVNXUuGsC2xNWVU0Qv0/w+4Q479HvE/wi20o+CX7/tud+gU3l1RSWVrKhpJLC0kpWriyjqLSKoCrifZ7gHoOqlFXVbLuHOJ/QuXUy3bJSaN+yBZmpCV4VXQKZXlVdvF+orlGqvcRaXROkusa99/ZSlj+ktOWjRby/wdqULEEYYyLKfeEm0Co52pFE3ubyapZtKGV5YRnLC0tZsaGM5YVl5K/aRHF5db19TrxftpXwkuL9tEtP4qVrh9Xb+9eyBGGMMfWkZXI8gzpnMKhzxi7HqgJBNpVXUVjiquY2lFRSE1Ti44T42jYc71HZ3hZSue2xZodBlbWdB7ZW1ZAUH5lOA5YgjDGmASTE+chOTyK7Ca1FEtGKLBE5SUQWichSEbkjzPFEEXnROz5dRLqGHLvT279IREZFMk5jjDG7iliCEBE/8AhwMtAXuEBE+u502lXAJlXtATwA/Nm7ti8wBjgYOAn4t/d+xhhjGkgkSxBDgaWqulxVq4AJwOk7nXM68Kz3/BXgOHHdF04HJqhqpaquAJZ672eMMaaBRDJBdARWh7wu8PaFPUdVA8BmILOO1wIgImNFJF9E8gsLC+spdGOMMU17FAegquNUNU9V87Kydj8oyBhjzL6JZIJYA3QKeZ3j7Qt7jojEAS2Bojpea4wxJoIimSBmAD1FJFdEEnCNzhN3OmcicJn3/BzgE3XTy04Exni9nHKBnsDXEYzVGGPMTiI2DkJVAyLyM+ADwA88parzROQeIF9VJwJPAv8VkaXARlwSwTvvJWA+EABuUNWasB9kjDEmImJqPQgRKQRW7eflbYAN9RhOU2D3HPua2/2C3fO+6qKqYRtwYypBHAgRyd/dohmxyu459jW3+wW75/rU5HsxGWOMiQxLEMYYY8KyBLHduGgHEAV2z7Gvud0v2D3XG2uDMMYYE5aVIIwxxoRlCcIYY0xYzT5B7G3NilggIk+JyHoRmRuyr7WITBKRJd7jrktgNWEi0klEPhWR+SIyT0Ru8vbH7H2LSJKIfC0is717/r23P9dbb2Wpt/5KQrRjrU8i4heRb0Xkbe91TN8vgIisFJHvRGSWiOR7++r9b7tZJ4g6rlkRC57BrasR6g7gY1XtCXzsvY4lAeBWVe0LHA7c4P2/jeX7rgSOVdX+wADgJBE5HLfOygPeuiubcOuwxJKbgAUhr2P9fmuNVNUBIeMf6v1vu1knCOq2ZkWTp6pTcFOZhApdi+NZ4IwGDSrCVPUHVf3Ge16C+wLpSAzftzql3st4b1PgWNx6KxBj9ywiOcBPgCe810IM3+9e1PvfdnNPEHVedyIGZavqD97zH4HsaAYTSd5StgOB6cT4fXvVLbOA9cAkYBlQ7K23ArH3N/5P4JdA0HudSWzfby0FPhSRmSIy1ttX73/bEZuszzQdqqoiEpP9nUUkFXgVuFlVt7gfmE4s3rc3qeUAEWkFvA4cFOWQIkZETgXWq+pMETkm2vE0sCNVdY2ItAUmicjC0IP19bfd3EsQzXndiXUi0h7Ae1wf5XjqnYjE45LD86r6mrc75u8bQFWLgU+BYUArb70ViK2/8eHAaBFZiasePhZ4kNi9321UdY33uB73Q2AoEfjbbu4Joi5rVsSq0LU4LgPejGIs9c6ri34SWKCq/wg5FLP3LSJZXskBEWkBnIBre/kUt94KxNA9q+qdqpqjql1x/3Y/UdWLiNH7rSUiKSKSVvscOBGYSwT+tpv9SGoROQVXj1m7ZsUfoxxSvROR8cAxuCmB1wF3AW8ALwGdcVOkn6eqOzdkN1kiciTwOfAd2+unf41rh4jJ+xaRfrjGST/ux99LqnqPiHTD/cJuDXwLXKyqldGLtP55VUy3qeqpsX6/3v297r2MA15Q1T+KSCb1/Lfd7BOEMcaY8Jp7FZMxxpjdsARhjDEmLEsQxhhjwrIEYYwxJixLEMYYY8KyBGFMIyAix9TORmpMY2EJwhhjTFiWIIzZByJysbfmwiwRecybHK9URB7w1mD4WESyvHMHiMg0EZkjIq/Xzs8vIj1E5CNv3YZvRKS79/apIvKKiCwUkecldOIoY6LAEoQxdSQifYDzgeGqOgCoAS4CUoB8VT0Y+Aw3Uh3gOeBXqtoPN6K7dv/zwCPeug1HALUzcA4EbsatTdINN9eQMVFjs7kaU3fHAYOBGd6P+xa4CdGCwIveOf8DXhORlkArVf3M2/8s8LI3h05HVX0dQFUrALz3+1pVC7zXs4CuwBeRvy1jwrMEYUzdCfCsqt65w06R3+503v7OXxM6X1AN9u/TRJlVMRlTdx8D53hz8NeuAdwF9++odvbQC4EvVHUzsElEjvL2XwJ85q1uVyAiZ3jvkSgiyQ16F8bUkf1CMaaOVHW+iPwGt5KXD6gGbgDKgKHesfW4dgpwUy4/6iWA5cAV3v5LgMdE5B7vPc5twNswps5sNldjDpCIlKpqarTjMKa+WRWTMcaYsKwEYYwxJiwrQRhjjAnLEoQxxpiwLEEYY4wJyxKEMcaYsCxBGGOMCev/AcYh+jmwSUMHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbYpwGbOsA0w"
      },
      "source": [
        "model.save('TransferLearning_ResNet50_oversampling_smoothLabels.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}