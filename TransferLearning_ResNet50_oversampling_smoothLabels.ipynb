{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning_ResNet50_oversampling_smoothLabels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1n4qlGG6aom4F9cFxwUod8qB-eQVvPr8t",
      "authorship_tag": "ABX9TyMZ/ZMp6Kcpv/7zwVAX5IcA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mitul01/FER/blob/main/TransferLearning_ResNet50_oversampling_smoothLabels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibb-suoVu23w"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsfpSp2Zu9ka",
        "outputId": "e1d1ecbd-123a-4d73-9e62-1338d2a049e6"
      },
      "source": [
        "cd /content/drive/MyDrive/colab-20210303T131708Z-001/colab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab-20210303T131708Z-001/colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppi9U9bC42_U"
      },
      "source": [
        "def make_6_emotions(df):\n",
        "  for i in range(len(df)):\n",
        "    if df['emotion'][i]==1:\n",
        "      df['emotion'][i]==0\n",
        "    elif df['emotion'][i]>1:\n",
        "      df['emotion'][i]-=1\n",
        "  return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFz6VAFCvBho",
        "outputId": "34b405d6-2097-4eea-fa4a-9a537479766f"
      },
      "source": [
        "data = pd.read_csv('fer2013/fer2013.csv')\n",
        "data= make_6_emotions(data)\n",
        "train_data = data[data.Usage=='Training']\n",
        "val_data = data[data.Usage=='PublicTest']\n",
        "test_data = data[data.Usage=='PrivateTest']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAdvxwMD4hY_"
      },
      "source": [
        "# Oversampling the data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x2Z8lOjvMpl",
        "outputId": "b81801c8-4d70-4642-a591-6f4aed14b4c3"
      },
      "source": [
        "import collections\n",
        "import imblearn\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversampler = RandomOverSampler()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79VwjNLX4j4s",
        "outputId": "00d663bc-df58-4b53-f539-535d68152346"
      },
      "source": [
        "collections.Counter(train_data.emotion)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 3995, 1: 4533, 2: 7215, 3: 4830, 4: 3171, 5: 4965})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gc7x_w259uD",
        "outputId": "d695a61e-daf8-4b31-cac4-560c72393271"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "x_train, y_train = oversampler.fit_resample(train_data.pixels.values.reshape(-1,1),train_data.emotion.values)\n",
        "\n",
        "x_val = val_data.pixels.values.reshape(-1,1)\n",
        "y_val = val_data.emotion.values\n",
        "\n",
        "x_test = test_data.pixels.values.reshape(-1,1)\n",
        "y_test = test_data.emotion.values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOGpKU8o6aC4",
        "outputId": "9f564d33-1cfd-4f71-e0d9-dacbccb7fb77"
      },
      "source": [
        "collections.Counter(y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 7215, 1: 7215, 2: 7215, 3: 7215, 4: 7215, 5: 7215})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs-33l0B6c5g"
      },
      "source": [
        "x_train = list(x_train)\n",
        "x_val   = list(x_val)\n",
        "x_test  = list(x_test)\n",
        "\n",
        "for i,item in enumerate(x_train):\n",
        "    x_train[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\n",
        "for i,item in enumerate(x_val):\n",
        "    x_val[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\n",
        "for i,item in enumerate(x_test):\n",
        "    x_test[i] = np.fromstring(item[0],sep=' ').reshape(48,48,1)\n",
        "    \n",
        "x_train = np.vstack(x_train).reshape(-1,48,48,1)\n",
        "x_val = np.vstack(x_val).reshape(-1,48,48,1)\n",
        "x_test = np.vstack(x_test).reshape(-1,48,48,1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeRrHcga6iAA"
      },
      "source": [
        "y_train = to_categorical(y_train,num_classes=6)\n",
        "y_val   = to_categorical(y_val  ,num_classes=6)\n",
        "y_test  = to_categorical(y_test ,num_classes=6)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7yVFs_HNXuN"
      },
      "source": [
        "# Label Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bue_PVUb6k3J"
      },
      "source": [
        "from copy import deepcopy as copy\n",
        "\n",
        "def smooth_labels(y, smooth_factor):\n",
        "    '''Convert a matrix of one-hot row-vector labels into smoothed versions.\n",
        "\n",
        "    # Arguments\n",
        "        y: matrix of one-hot row-vector labels to be smoothed\n",
        "        smooth_factor: label smoothing factor (between 0 and 1)\n",
        "\n",
        "    # Returns\n",
        "        A matrix of smoothed labels.\n",
        "    '''\n",
        "    assert len(y.shape) == 2, 'input should be a batch of one-hot-encoded data'\n",
        "    y2 = copy(y)\n",
        "    if 0 <= smooth_factor <= 1:\n",
        "        # label smoothing ref: https://www.robots.ox.ac.uk/~vgg/rg/papers/reinception.pdf\n",
        "        y2 *= 1 - smooth_factor\n",
        "        y2 += smooth_factor / y.shape[1]\n",
        "    else:\n",
        "        raise Exception(\n",
        "            'Invalid label smoothing factor: ' + str(smooth_factor))\n",
        "    return y2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib5OQn8C_7un"
      },
      "source": [
        "from keras.utils import Sequence\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "import cv2\n",
        "from math import floor\n",
        "\n",
        "class data_sequence(Sequence):\n",
        "    '''\n",
        "      yield sequence of data\n",
        "      features -- list of features\n",
        "      labels -- list of labels\n",
        "      target_channels {int} -- 1 (gray) or 3(RGB)\n",
        "    '''\n",
        "    def __init__(self, features, labels, batch_size=128, target_dim=(224,224), \n",
        "                 n_classes=6, shuffle=True, smooth=0.0):\n",
        "        'Initialization'\n",
        "        assert len(features)==len(labels), 'number of feature and labels not consistent'\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.batch_size = batch_size\n",
        "        self.target_dim = target_dim\n",
        "        self.target_channels = 3\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.smooth = smooth\n",
        "        self.sample_count = len(labels)\n",
        "        self.indexes = np.arange(self.sample_count)\n",
        "        self.on_epoch_end()\n",
        "#         self.verbose = verbose\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return floor(self.sample_count / self.batch_size)\n",
        "\n",
        "    def __gray2RGB__(self,x):\n",
        "      if len(x.shape)==2:\n",
        "        return np.stack((x,x,x),-1)\n",
        "      else:\n",
        "        assert len(x.shape)==3\n",
        "        if len(x[0,0,:]) == 1:\n",
        "          return np.stack((x[:,:,0],x[:,:,0],x[:,:,0]),-1)\n",
        "        else:\n",
        "          assert len(x[0,0,:])==self.target_channels\n",
        "      return x\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        X = np.empty((self.batch_size, *self.target_dim, self.target_channels))\n",
        "        Y = np.empty((self.batch_size, self.n_classes))\n",
        "        for i,ind in enumerate(indexes):\n",
        "          x = self.features[ind]\n",
        "          # resize image to the target size \n",
        "          x = cv2.resize(x,self.target_dim,interpolation=cv2.INTER_CUBIC)\n",
        "          x = self.__gray2RGB__(x)\n",
        "          X[i] = preprocess_input(x) # or version=2 for VGGFace2 ResNet50  \n",
        "          y = self.labels[ind]\n",
        "          if isinstance(y,int):\n",
        "            Y[i]=to_categorical(y,6)\n",
        "          else:\n",
        "            assert len(y)==self.n_classes\n",
        "            Y[i]=y\n",
        "        X = np.array(X)\n",
        "        Y = np.array(Y)\n",
        "        if self.smooth > 0.0:\n",
        "          smooth_labels(Y, self.smooth)\n",
        "        return X,Y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdvyGOpnBR6Q"
      },
      "source": [
        "train_sequence = data_sequence(x_train,y_train,batch_size=16,target_dim=(224,224),n_classes=6,shuffle=False)\n",
        "feature,lable = train_sequence.__getitem__(0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9Qm38XTBf5b"
      },
      "source": [
        "emotion_dict = {0: 'Angry',1: 'Fear', 2: 'Happy', 3: 'Sad', 4: 'Surprise', 5:'Neutral'}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS21WTK9EL1l",
        "outputId": "b97f8c93-e36a-4d0d-d83e-8d3224457a15"
      },
      "source": [
        "!pip install keras-vggface\n",
        "!pip install keras_applications\n",
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-vggface\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/7d/5f0319ebdc09ac1a2272364fa9583f5067b6f8aff93fbbf8835d81cbaad7/keras_vggface-0.6-py3-none-any.whl\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (7.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-vggface) (1.19.5)\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n",
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_2zFgjtEF7p",
        "outputId": "2ac753d4-6170-4086-86b1-a52eb60ddd02"
      },
      "source": [
        "vggface = VGGFace(model='resnet50', include_top=False, input_shape = (224,224,3))\n",
        "vggface.trainable = False\n",
        "vggface.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_resnet50.h5\n",
            "94699520/94694792 [==============================] - 3s 0us/step\n",
            "Model: \"vggface_resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2 (Conv2D)           (None, 112, 112, 64) 9408        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1/7x7_s2/bn (BatchNormaliza (None, 112, 112, 64) 256         conv1/7x7_s2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 112, 112, 64) 0           conv1/7x7_s2/bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce (Conv2D)     (None, 55, 55, 64)   4096        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 55, 55, 64)   0           conv2_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           conv2_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj (Conv2D)       (None, 55, 55, 256)  16384       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_1x1_proj/bn (BatchNorma (None, 55, 55, 256)  1024        conv2_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 55, 55, 256)  0           conv2_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv2_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 64)   0           conv2_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           conv2_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           conv2_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce (Conv2D)     (None, 55, 55, 64)   16384       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_reduce/bn (BatchNor (None, 55, 55, 64)   256         conv2_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 64)   0           conv2_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3 (Conv2D)            (None, 55, 55, 64)   36864       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_3x3/bn (BatchNormalizat (None, 55, 55, 64)   256         conv2_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           conv2_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase (Conv2D)   (None, 55, 55, 256)  16384       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_1x1_increase/bn (BatchN (None, 55, 55, 256)  1024        conv2_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           conv2_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce (Conv2D)     (None, 28, 28, 128)  32768       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 128)  0           conv3_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           conv3_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj (Conv2D)       (None, 28, 28, 512)  131072      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_1x1_proj/bn (BatchNorma (None, 28, 28, 512)  2048        conv3_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 512)  0           conv3_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv3_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 128)  0           conv3_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           conv3_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           conv3_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 128)  0           conv3_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           conv3_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           conv3_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce (Conv2D)     (None, 28, 28, 128)  65536       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_reduce/bn (BatchNor (None, 28, 28, 128)  512         conv3_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 128)  0           conv3_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3 (Conv2D)            (None, 28, 28, 128)  147456      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_3x3/bn (BatchNormalizat (None, 28, 28, 128)  512         conv3_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           conv3_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase (Conv2D)   (None, 28, 28, 512)  65536       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_1x1_increase/bn (BatchN (None, 28, 28, 512)  2048        conv3_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           conv3_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce (Conv2D)     (None, 14, 14, 256)  131072      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 14, 14, 256)  0           conv4_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           conv4_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj (Conv2D)       (None, 14, 14, 1024) 524288      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_1x1_proj/bn (BatchNorma (None, 14, 14, 1024) 4096        conv4_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 1024) 0           conv4_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv4_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 256)  0           conv4_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           conv4_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           conv4_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 256)  0           conv4_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           conv4_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           conv4_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_4_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 256)  0           conv4_4_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_4_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           conv4_4_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_4_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           conv4_4_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_5_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 256)  0           conv4_5_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_5_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           conv4_5_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_5_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           conv4_5_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce (Conv2D)     (None, 14, 14, 256)  262144      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_reduce/bn (BatchNor (None, 14, 14, 256)  1024        conv4_6_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 256)  0           conv4_6_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3 (Conv2D)            (None, 14, 14, 256)  589824      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_3x3/bn (BatchNormalizat (None, 14, 14, 256)  1024        conv4_6_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           conv4_6_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase (Conv2D)   (None, 14, 14, 1024) 262144      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_1x1_increase/bn (BatchN (None, 14, 14, 1024) 4096        conv4_6_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           conv4_6_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce (Conv2D)     (None, 7, 7, 512)    524288      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_1_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 512)    0           conv5_1_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_1_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           conv5_1_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj (Conv2D)       (None, 7, 7, 2048)   2097152     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_1_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_1x1_proj/bn (BatchNorma (None, 7, 7, 2048)   8192        conv5_1_1x1_proj[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 2048)   0           conv5_1_1x1_increase/bn[0][0]    \n",
            "                                                                 conv5_1_1x1_proj/bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_2_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 512)    0           conv5_2_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_2_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           conv5_2_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_2_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           conv5_2_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce (Conv2D)     (None, 7, 7, 512)    1048576     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_reduce/bn (BatchNor (None, 7, 7, 512)    2048        conv5_3_1x1_reduce[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 512)    0           conv5_3_1x1_reduce/bn[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3 (Conv2D)            (None, 7, 7, 512)    2359296     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_3x3/bn (BatchNormalizat (None, 7, 7, 512)    2048        conv5_3_3x3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           conv5_3_3x3/bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase (Conv2D)   (None, 7, 7, 2048)   1048576     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_1x1_increase/bn (BatchN (None, 7, 7, 2048)   8192        conv5_3_1x1_increase[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           conv5_3_1x1_increase/bn[0][0]    \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_48[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 23,561,152\n",
            "Trainable params: 0\n",
            "Non-trainable params: 23,561,152\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLWquPTkEKoO",
        "outputId": "bb7770f3-b0ea-4605-dbda-7847debacadb"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "# model = Sequential([vggface,\n",
        "#                     Flatten(),\n",
        "#                     Dropout(0.5),\n",
        "#                     BatchNormalization(),\n",
        "#                     Dense(128, activation='relu'),\n",
        "#                     Dropout(0.5),\n",
        "#                     BatchNormalization(),\n",
        "#                     Dense(len(emotion_dict), activation='softmax', name = 'classifer')])\n",
        "model = Sequential([vggface,\n",
        "                    Flatten(),\n",
        "                    Dropout(0.25),\n",
        "                    Dense(2048, activation='relu'),\n",
        "                    Dropout(0.25),\n",
        "                    Dense(1024, activation='relu'),\n",
        "                    Dense(6, activation='softmax', name = 'classifer')])\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vggface_resnet50 (Functional (None, 1, 1, 2048)        23561152  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "classifer (Dense)            (None, 6)                 6150      \n",
            "=================================================================\n",
            "Total params: 29,861,830\n",
            "Trainable params: 6,300,678\n",
            "Non-trainable params: 23,561,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGa11LWgEopS"
      },
      "source": [
        "train_sequence = data_sequence(x_train,y_train,batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.07)\n",
        "val_sequence   = data_sequence(x_val,  y_val,  batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\n",
        "test_sequence  = data_sequence(x_test, y_test, batch_size=64,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\n",
        "\n",
        "#train_sequence = data_sequence(x_train,y_train,batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.07)\n",
        "#val_sequence   = data_sequence(x_val,  y_val,  batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)\n",
        "#test_sequence  = data_sequence(x_test, y_test, batch_size=32,target_dim=(224,224),n_classes=6,shuffle=True,smooth=0.0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0avPy4szExop",
        "outputId": "df04b5e2-5111-4ce4-f0db-0cad68844e64"
      },
      "source": [
        "EPOCHS=100\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, TensorBoard, ModelCheckpoint\n",
        "\n",
        "model.compile(optimizer = Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    min_delta=0.00005,\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-7,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    early_stopping,\n",
        "    lr_scheduler,\n",
        "]\n",
        "\n",
        "hist = model.fit_generator(generator = train_sequence,\n",
        "                           validation_data = val_sequence,\n",
        "                           callbacks=callbacks,\n",
        "                           epochs = EPOCHS)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "676/676 [==============================] - 156s 178ms/step - loss: 2.0656 - accuracy: 0.4694 - val_loss: 1.0428 - val_accuracy: 0.5954\n",
            "Epoch 2/100\n",
            "676/676 [==============================] - 123s 181ms/step - loss: 0.9900 - accuracy: 0.6254 - val_loss: 1.0207 - val_accuracy: 0.6110\n",
            "Epoch 3/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.8526 - accuracy: 0.6818 - val_loss: 1.0392 - val_accuracy: 0.6164\n",
            "Epoch 4/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.7464 - accuracy: 0.7210 - val_loss: 0.9938 - val_accuracy: 0.6359\n",
            "Epoch 5/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.6661 - accuracy: 0.7594 - val_loss: 0.9853 - val_accuracy: 0.6526\n",
            "Epoch 6/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.5993 - accuracy: 0.7817 - val_loss: 0.9999 - val_accuracy: 0.6490\n",
            "Epoch 7/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.5392 - accuracy: 0.8049 - val_loss: 1.0450 - val_accuracy: 0.6406\n",
            "Epoch 8/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.5000 - accuracy: 0.8215 - val_loss: 1.0726 - val_accuracy: 0.6504\n",
            "Epoch 9/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.4556 - accuracy: 0.8385 - val_loss: 1.0639 - val_accuracy: 0.6554\n",
            "Epoch 10/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.4244 - accuracy: 0.8499 - val_loss: 1.0984 - val_accuracy: 0.6476\n",
            "Epoch 11/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.3949 - accuracy: 0.8590 - val_loss: 1.0849 - val_accuracy: 0.6579\n",
            "Epoch 12/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.3796 - accuracy: 0.8675 - val_loss: 1.1732 - val_accuracy: 0.6529\n",
            "Epoch 13/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.3643 - accuracy: 0.8719 - val_loss: 1.1631 - val_accuracy: 0.6610\n",
            "Epoch 14/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.3463 - accuracy: 0.8801 - val_loss: 1.1466 - val_accuracy: 0.6568\n",
            "Epoch 15/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.3156 - accuracy: 0.8898 - val_loss: 1.1766 - val_accuracy: 0.6596\n",
            "Epoch 16/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.3078 - accuracy: 0.8941 - val_loss: 1.1672 - val_accuracy: 0.6582\n",
            "Epoch 17/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.3089 - accuracy: 0.8939 - val_loss: 1.2652 - val_accuracy: 0.6646\n",
            "Epoch 18/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.2880 - accuracy: 0.8988 - val_loss: 1.2536 - val_accuracy: 0.6635\n",
            "Epoch 19/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.2762 - accuracy: 0.9036 - val_loss: 1.2313 - val_accuracy: 0.6696\n",
            "Epoch 20/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.2677 - accuracy: 0.9099 - val_loss: 1.2521 - val_accuracy: 0.6560\n",
            "Epoch 21/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.2726 - accuracy: 0.9067 - val_loss: 1.3810 - val_accuracy: 0.6635\n",
            "Epoch 22/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.2587 - accuracy: 0.9105 - val_loss: 1.2947 - val_accuracy: 0.6682\n",
            "Epoch 23/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.2475 - accuracy: 0.9149 - val_loss: 1.2814 - val_accuracy: 0.6657\n",
            "Epoch 24/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.2364 - accuracy: 0.9197 - val_loss: 1.3347 - val_accuracy: 0.6618\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 25/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.1955 - accuracy: 0.9305 - val_loss: 1.3431 - val_accuracy: 0.6780\n",
            "Epoch 26/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.1555 - accuracy: 0.9463 - val_loss: 1.3693 - val_accuracy: 0.6777\n",
            "Epoch 27/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.1568 - accuracy: 0.9454 - val_loss: 1.4568 - val_accuracy: 0.6738\n",
            "Epoch 28/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.1471 - accuracy: 0.9479 - val_loss: 1.4588 - val_accuracy: 0.6766\n",
            "Epoch 29/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.1432 - accuracy: 0.9510 - val_loss: 1.5146 - val_accuracy: 0.6769\n",
            "Epoch 30/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.1440 - accuracy: 0.9519 - val_loss: 1.4497 - val_accuracy: 0.6752\n",
            "\n",
            "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 31/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.1177 - accuracy: 0.9598 - val_loss: 1.5289 - val_accuracy: 0.6825\n",
            "Epoch 32/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.1096 - accuracy: 0.9615 - val_loss: 1.5939 - val_accuracy: 0.6808\n",
            "Epoch 33/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.0998 - accuracy: 0.9636 - val_loss: 1.6210 - val_accuracy: 0.6735\n",
            "Epoch 34/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.1022 - accuracy: 0.9637 - val_loss: 1.6274 - val_accuracy: 0.6789\n",
            "Epoch 35/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.0980 - accuracy: 0.9655 - val_loss: 1.6553 - val_accuracy: 0.6766\n",
            "Epoch 36/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.0945 - accuracy: 0.9659 - val_loss: 1.6968 - val_accuracy: 0.6805\n",
            "\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 37/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.0922 - accuracy: 0.9669 - val_loss: 1.6400 - val_accuracy: 0.6733\n",
            "Epoch 38/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.0818 - accuracy: 0.9711 - val_loss: 1.6847 - val_accuracy: 0.6805\n",
            "Epoch 39/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.0793 - accuracy: 0.9731 - val_loss: 1.7162 - val_accuracy: 0.6839\n",
            "Epoch 40/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.0793 - accuracy: 0.9717 - val_loss: 1.7261 - val_accuracy: 0.6808\n",
            "Epoch 41/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.0774 - accuracy: 0.9733 - val_loss: 1.7463 - val_accuracy: 0.6791\n",
            "Epoch 42/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 1.7536 - val_accuracy: 0.6744\n",
            "Epoch 43/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.0751 - accuracy: 0.9741 - val_loss: 1.7885 - val_accuracy: 0.6755\n",
            "Epoch 44/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.0736 - accuracy: 0.9733 - val_loss: 1.8047 - val_accuracy: 0.6808\n",
            "\n",
            "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 45/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.0714 - accuracy: 0.9743 - val_loss: 1.7832 - val_accuracy: 0.6786\n",
            "Epoch 46/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.0670 - accuracy: 0.9765 - val_loss: 1.7935 - val_accuracy: 0.6800\n",
            "Epoch 47/100\n",
            "676/676 [==============================] - 124s 183ms/step - loss: 0.0651 - accuracy: 0.9753 - val_loss: 1.8201 - val_accuracy: 0.6805\n",
            "Epoch 48/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.0628 - accuracy: 0.9764 - val_loss: 1.8239 - val_accuracy: 0.6780\n",
            "Epoch 49/100\n",
            "676/676 [==============================] - 124s 184ms/step - loss: 0.0641 - accuracy: 0.9763 - val_loss: 1.7957 - val_accuracy: 0.6777\n",
            "Restoring model weights from the end of the best epoch.\n",
            "\n",
            "Epoch 00049: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 00049: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqCCaS7QMdOH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b01aca-99c9-470d-f192-58716d56d91a"
      },
      "source": [
        "model.evaluate(test_sequence)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56/56 [==============================] - 10s 169ms/step - loss: 1.5376 - accuracy: 0.6900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.5375754833221436, 0.6900111436843872]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9q4DZqeQr72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "e7c37162-0a81-4c09-c112-27ab1a28286d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'dev'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbYpwGbOsA0w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}